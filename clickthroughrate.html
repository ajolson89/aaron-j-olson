
<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Click Through Rate Prediction</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta name="author" content="Aaron Olson, Daniel Elkin & Roger Leung" />
    <meta name="description" content="Utilization of big data workflows in Spark to implement gradient boosted tree algorithm to predict CTR" />
    <meta name="keywords" content="python, gradient boost, decision tree, spark, pyspark">
<!-- Facebook and Twitter integration -->
<meta property="og:site_name" content="Aaron J. Olson - Portfolio"/>
<meta property="og:title" content="Click Through Rate Prediction"/>
<meta property="og:description" content="Utilization of big data workflows in Spark to implement gradient boosted tree algorithm to predict CTR"/>
<meta property="og:url" content="https://aaron-j-olson.com/clickthroughrate.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-06-08 20:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://aaron-j-olson.com/author/aaron-olson-daniel-elkin-roger-leung.html">
<meta property="article:section" content="posts"/>
    <meta property="article:tag" content="python"/>
    <meta property="article:tag" content="gradient boost"/>
    <meta property="article:tag" content="decision tree"/>
    <meta property="article:tag" content="spark"/>
    <meta property="article:tag" content="pyspark"/>
    <meta property="og:image" content="\images\olson.jpg">

    <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700" rel="stylesheet">

    <!-- Animate.css -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/animate.css">
    <!-- Icomoon Icon Fonts-->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/icomoon.css">
    <!-- Bootstrap  -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/bootstrap.css">
    <!-- Flexslider  -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/flexslider.css">
    <!-- Theme style  -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/style.css">
    <!-- Custom style  -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/custom.css">
    <!-- pygments code highlight -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/css/pygments.css">
    <!-- tipue search -->
    <link rel="stylesheet" href="https://aaron-j-olson.com/theme/tipuesearch/css/tipuesearch.css">

    <!-- Modernizr JS -->
    <script src="https://aaron-j-olson.com/theme/js/modernizr-2.6.2.min.js"></script>
    <!-- FOR IE9 below -->
    <!--[if lt IE 9]>
    <script src="/theme/js/respond.min.js"></script>
    <![endif]-->
        <link href="https://aaron-j-olson.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Aaron J. Olson - Portfolio Atom">



    </head>
    <body>
    <div id="fh5co-page">
        <a href="#" class="js-fh5co-nav-toggle fh5co-nav-toggle"><i></i></a>
        <aside id="fh5co-aside" role="complementary" class="border js-fullheight">

            <nav class="fh5co-main-menu" role="navigation">
            </nav>
            <div class="clearfix"></div>
            <h1  id="fh5co-logo">
                <a href="https://aaron-j-olson.com/index.html">
                    <img src="\images\olson.jpg" />
                </a>
            </h1>
            <nav class="fh5co-main-menu" role="navigation">
<ul>
    <!-- home link -->
    <li><a href="https://aaron-j-olson.com/">Home</a></li>

    <!-- page links -->
            <li><a href="https://aaron-j-olson.com/pages/home.html">About Me</a></li>

    <!-- categories -->
        <li><a href="https://aaron-j-olson.com/categories.html">Categories</a></li>

    <!-- tags -->
        <li><a href="https://aaron-j-olson.com/tags.html">Tags</a></li>

    <!-- additional menu items from config -->
        <!-- <li class="nav-title">Misc</li> -->
            <li><a href="https://aaron-j-olson.com/archives.html">Archive</a></li>
            <li><a href="https://aaron-j-olson.com/contact.html">Contact</a></li>

</ul>
            </nav>

<ul id="social">
            <li><a href="https://github.com/ajolson89" alt="Github"><i class="icon-github"></i></a></li>

            <li><a href="https://www.linkedin.com/in/aaron-j-olson/" alt="LinkedIn"><i class="icon-linkedin2"></i></a></li>

</ul>
        </aside>

        <div id="fh5co-main">

    <div class="fh5co-narrow-content article-content">
        <h1 class="fh5co-heading-colored">Click Through Rate Prediction</h1>

        <div>by
                <a href="author/aaron-olson-daniel-elkin-roger-leung.html">Aaron Olson, Daniel Elkin & Roger Leung</a> - Sat 08 June 2019
        </div>

            <div><span>Tags: </span>
                    <span><a href="https://aaron-j-olson.com/tag/python.html">#python</a> </span>
                    <span><a href="https://aaron-j-olson.com/tag/gradient-boost.html">#gradient boost</a> </span>
                    <span><a href="https://aaron-j-olson.com/tag/decision-tree.html">#decision tree</a> </span>
                    <span><a href="https://aaron-j-olson.com/tag/spark.html">#spark</a> </span>
                    <span><a href="https://aaron-j-olson.com/tag/pyspark.html">#pyspark</a> </span>
            </div>

        <div class="animate-box" data-animate-effect="fadeInLeft">
            <p class="animate-box" data-animate-effect="fadeInLeft"><p>Table of Contents
Section 1 - Question Formulation
Section 3 - EDA &amp; Challenges
Section 1 - Question Formulation 
In this notebook, we build a model to perform clickthrough rate prediction using a public dataset from CriteoLabs, which is available here: https://www.kaggle.com/c/criteo-display-ad-challenge/data.</p>
<p>Clickthrough rate, or CTR, is a metric used by advertisers to determine how effectively their ads are attracting visitors to their websites or products and is the ratio of the number of times an ad has been clicked to the number of times an ad has been shown (https://support.google.com/google-ads/answer/2615875?hl=en). A relatively high CTR means that users are being show relevant ads, and advertisers and ad publishers thus want to maximize CTR in order to attract the most possible users and maximize profits.</p>
<p>The dataset used here contains seven days of data from Criteo, an ad targeting company. There is one target column for each row that indicates whether or not an ad was clicked and 39 feature columns. While we are not told what each feature represents, we know that they are data related to the publisher, the advertiser, the user and interactions between the user and the advertiser (https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/9568#49738). The task is then to use these features to predict whether or not an ad was clicked.</p>
<p>In general, the average CTR is less than two percent across industries, so a model that achieves better performance would be practically useful (https://blog.hubspot.com/agency/google-adwords-benchmark-data). As we'll see below, this particular dataset has a mean CTR of about 25%. The baseline accuracy we'll seek to exceed is thus 75%, as this would be the accuracy a model would achieve by simply predicting the negative class in all cases. The model we'll use here is a decision tree.</p>
<h3>Decision Tree and Gradient Boosting in Python</h3>
<p>In our analysis for click through rate we will implement the gradient boosting algorithm in order to fit a number of decision trees to the feature space. With the goal of predicting the proportion of clicks in order to determine the most beneficial add space, we will need to properly assess whether or no a user is likely to click on an add given the 38 features we have in our dataset. </p>
<p>First we will discuss the method to fit a single decision tree in python, we will then expand this to the basis of gradient boost which will be the algorithm we will utilize on our full CTR dataset. </p>
<p><strong>Single Decision Tree</strong></p>
<p>The goal of a decision tree is to split up the rows into pure samples by splitting up based on a feature value. We take a number of splits in order to do so. For example, if our decision tree were attempting to determine whether a sign is a stop sign (amongst examples of signs), one decision could be whether the sign was red or not. Presumably this would make the sample space more pure as all stop signs are red, whereas if a sign isn't red it won't be in the true split (our negative split is 100% pure for non-stop sign). We would then ask further questions of our true split to continue to filter down. Because we can presumably develop trees until there is a single example in each leaf (terminating node) decision trees are prone to overfitting. To prevent a tree from overfitting, we can set a minimum number of examples in a leaf node, if a returned branch is smaller than this value we cannot split make the split, this is the same as early termination in other machine learning routines. </p>
<p>To make the most judicious split we have to sample at every potential split (greedy algorithm). In the case of categorical features we can make use of the Brieman technique where we divide the feature by value and sort by mean target variable. For example, if our feature has values a, b and c and the means of the target variable (binary coded as 0 / 1) is 0.1, 0.8, 0.3 respectively, we would order our values a, c and b. We can then walk through the splits sequentially to reduce the number of total splits required. </p>
<p>By iterating over each feature / column and each value in each feature we compute the best score metric and keep track of which feature and value produces the best score. There are a number of score metrics that can be used, in the example below we use the gini score. </p>
<p>The gini score is defined as: $\sum_{k}^{K} = p_{mk} * (1-p_{mk})$ where $p_{mk} =$ proportion of class k in partition m $ = \frac{1}{N_m} \sum I(y_i = k)$</p>
<p>The Gini score takes the proportion that are correctly classified and multiply by the proportion that isn't correctly classified, summing over all classes of the target variable. A Gini index score of 0 means perfect segregation given the data. Gini allows us a more complex method to compute error for a classification target variable. </p>
<p>We compute the gini index for a potential split point for a specific variable and then compute the information gained. Our best split point is defined as the split that gives us the most information gained. Information gain is defined as: $Gain = Current Uncertainty - (\frac{n_{LHS}}{N} Gini_{LHS} + (1-\frac{n_{LHS}}{N}) Gini_{RHS})$. After iterating across all potential variables and split points we choose the split that generates the highest information gain. We then recursively call the algorithm until the entire tree structure is defined. </p>
<p>The goal of a single decision tree is to create branch points that have the highest purity of outcome variable possible as mentioned earlier. Below we represent the python code and build a tree for a toy dataset. There are limitations with a single decision tree which will be discussed down below when we address gradient boost techniques. </p>
<div class="highlight"><pre><span></span><span class="c1"># imports</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">types</span>
<span class="kn">import</span> <span class="nn">pyspark.sql</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span>

<span class="c1"># start Spark Session</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">app_name</span> <span class="o">=</span> <span class="s2">&quot;hw3_notebook&quot;</span>
<span class="n">master</span> <span class="o">=</span> <span class="s2">&quot;local[*]&quot;</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span>\
        <span class="o">.</span><span class="n">builder</span>\
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="n">app_name</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># create RDDs</span>
<span class="n">trainRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;./data/train.txt&quot;</span><span class="p">)</span>
<span class="n">testRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;./data/test.txt&quot;</span><span class="p">)</span>
<span class="n">toytrainRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s1">&#39;./data/toy_train.txt&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">TOY_FILE</span> <span class="o">=</span> <span class="s2">&quot;./data/train.tiny.csv&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TOY_FILE</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Id&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Label</th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>...</th>
      <th>C17</th>
      <th>C18</th>
      <th>C19</th>
      <th>C20</th>
      <th>C21</th>
      <th>C22</th>
      <th>C23</th>
      <th>C24</th>
      <th>C25</th>
      <th>C26</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1.0</td>
      <td>1</td>
      <td>5.0</td>
      <td>0.0</td>
      <td>1382.0</td>
      <td>4.0</td>
      <td>15.0</td>
      <td>2.0</td>
      <td>181.0</td>
      <td>...</td>
      <td>e5ba7672</td>
      <td>f54016b9</td>
      <td>21ddcdc9</td>
      <td>b1252a9d</td>
      <td>07b5194c</td>
      <td>NaN</td>
      <td>3a171ecb</td>
      <td>c5c50484</td>
      <td>e8b83407</td>
      <td>9727dd16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2.0</td>
      <td>0</td>
      <td>44.0</td>
      <td>1.0</td>
      <td>102.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>...</td>
      <td>07c540c4</td>
      <td>b04e4670</td>
      <td>21ddcdc9</td>
      <td>5840adea</td>
      <td>60f6221e</td>
      <td>NaN</td>
      <td>3a171ecb</td>
      <td>43f13e8b</td>
      <td>e8b83407</td>
      <td>731c3655</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>2.0</td>
      <td>0</td>
      <td>1.0</td>
      <td>14.0</td>
      <td>767.0</td>
      <td>89.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>245.0</td>
      <td>...</td>
      <td>8efede7f</td>
      <td>3412118d</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>e587c466</td>
      <td>ad3062eb</td>
      <td>3a171ecb</td>
      <td>3b183c5c</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>NaN</td>
      <td>893</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4392.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1e88c74f</td>
      <td>74ef3502</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6b3a5ca6</td>
      <td>NaN</td>
      <td>3a171ecb</td>
      <td>9117a34a</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3.0</td>
      <td>-1</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>1e88c74f</td>
      <td>26b3c7a7</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>21c9516a</td>
      <td>NaN</td>
      <td>32c7478e</td>
      <td>b34f3128</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 40 columns</p>
</div>

<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gini_index</span><span class="p">(</span><span class="n">gini_df</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute the gini index for categorical features/variables</span>
<span class="sd">    Input: </span>
<span class="sd">        gini_df: pandas dataframe used to compute gini index</span>
<span class="sd">    Returns: </span>
<span class="sd">        impurity: gini index score of the dataframe</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">total_size</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">size</span>
    <span class="n">gini</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gini_df</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="n">counts</span> <span class="o">=</span> <span class="n">gini_df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    <span class="c1"># score the group based on the score for each class</span>
    <span class="n">impurity</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="p">:</span>
        <span class="n">prob_of_lbl</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">gini_df</span><span class="p">[</span><span class="n">gini_df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">count</span><span class="p">])</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gini_df</span><span class="p">))</span>
        <span class="n">impurity</span> <span class="o">-=</span> <span class="n">prob_of_lbl</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">impurity</span>

<span class="k">def</span> <span class="nf">test_split</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Split a dataframe on a condition in order to  represent a node on a tree</span>
<span class="sd">    Input: </span>
<span class="sd">        index: column name of feature/variable to perform split</span>
<span class="sd">        value: value of feature value to split at</span>
<span class="sd">        dataset: dataset to be split</span>
<span class="sd">    Returns:</span>
<span class="sd">        left: dataset that is less than or equal to value if numeri or equal to value if categorical</span>
<span class="sd">        right: dataset that is greater than or not equal to the value</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">left</span><span class="p">,</span> <span class="n">right</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(),</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="c1"># test if variable is numeric or categorical</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">float</span><span class="p">):</span>
            <span class="n">left</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">value</span><span class="p">]</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">value</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">left</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="n">value</span><span class="p">]</span>
        <span class="n">right</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">!=</span> <span class="n">value</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">left</span><span class="p">,</span> <span class="n">right</span>

<span class="k">def</span> <span class="nf">info_gain</span><span class="p">(</span><span class="n">left</span><span class="p">,</span> <span class="n">right</span><span class="p">,</span> <span class="n">current_uncertainty</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Using the Gini index, compute the information gain to quantify the best split point</span>
<span class="sd">    Inputs: </span>
<span class="sd">        left: pandas dataframe of true branch from previous split</span>
<span class="sd">        right: pandas dataframe of right branch from previous split</span>
<span class="sd">        current_uncertainty: the gini-index of the parent node</span>

<span class="sd">    Returns: </span>
<span class="sd">        In information gained based on the tree splits and previous gini-index</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">p</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">left</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">left</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">right</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">current_uncertainty</span> <span class="o">-</span> <span class="n">p</span> <span class="o">*</span> <span class="n">gini_index</span><span class="p">(</span><span class="n">left</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">gini_index</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">find_best_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Uses the Brieman method for categorical variables and each split point for numeric variables</span>
<span class="sd">    to test at every potential split point across the feature space to compute the gini index and information </span>
<span class="sd">    gain in order to determine the optimal split point and splitting value given the present state</span>

<span class="sd">    Inputs: </span>
<span class="sd">        dataset: pandas dataframe consisting of the variables and data</span>
<span class="sd">    Returns: </span>
<span class="sd">        best_gain: the best gain score given the optimal split point</span>
<span class="sd">        best_var_split: the variable and value that produces the best split</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">best_gain</span> <span class="o">=</span> <span class="mi">0</span>  
    <span class="n">best_var_split</span> <span class="o">=</span> <span class="kc">None</span>  
    <span class="n">current_uncertainty</span> <span class="o">=</span> <span class="n">gini_index</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Label&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">col</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()[</span><span class="o">~</span><span class="n">numpy</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">col</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">()</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>  <span class="c1"># for each value</span>
            <span class="c1"># try splitting the dataset</span>
            <span class="n">true_rows</span><span class="p">,</span> <span class="n">false_rows</span> <span class="o">=</span> <span class="n">test_split</span><span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>

            <span class="c1"># Skip this split if it doesn&#39;t divide the</span>
            <span class="c1"># dataset.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">true_rows</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">false_rows</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Calculate the information gain from this split</span>
            <span class="n">gain</span> <span class="o">=</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">true_rows</span><span class="p">,</span> <span class="n">false_rows</span><span class="p">,</span> <span class="n">current_uncertainty</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">gain</span> <span class="o">&gt;=</span> <span class="n">best_gain</span><span class="p">:</span>
                <span class="n">best_gain</span><span class="p">,</span> <span class="n">best_var_split</span> <span class="o">=</span> <span class="n">gain</span><span class="p">,</span> <span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">best_gain</span><span class="p">,</span> <span class="n">best_var_split</span>

<span class="k">def</span> <span class="nf">class_counts</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    function to return the average proportion of results belonging to a particular class</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>

<span class="k">def</span> <span class="nf">build_tree</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Fucntion that is called recursively to build a single tree</span>
<span class="sd">    Inputs: </span>
<span class="sd">        dataset: dataset to perform tree building on</span>
<span class="sd">    Retruns: </span>
<span class="sd">        best_var_split: tuple containing feature adn value to perform split</span>
<span class="sd">        left: dataset for left branch</span>
<span class="sd">        right: dataset for right branch</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">class_counts</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="n">gain</span><span class="p">,</span> <span class="n">best_var_split</span> <span class="o">=</span> <span class="n">find_best_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">index</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">best_var_split</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">gain</span><span class="p">)</span>
    <span class="c1"># Base case: no further info gain</span>
    <span class="c1"># Since we can ask no further questions,</span>
    <span class="c1"># we&#39;ll return a leaf.</span>
    <span class="k">if</span> <span class="n">gain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">class_counts</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># If we reach here, we have found a useful feature / value</span>
    <span class="c1"># to partition on.</span>
    <span class="n">true_rows</span><span class="p">,</span> <span class="n">false_rows</span> <span class="o">=</span> <span class="n">test_split</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">dataset</span><span class="p">)</span>
    <span class="n">true_rows</span> <span class="o">=</span> <span class="n">true_rows</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">false_rows</span> <span class="o">=</span> <span class="n">false_rows</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Recursively build the true branch.</span>
    <span class="n">true_branch</span> <span class="o">=</span> <span class="n">build_tree</span><span class="p">(</span><span class="n">true_rows</span><span class="p">)</span>

    <span class="c1"># Recursively build the false branch.</span>
    <span class="n">false_branch</span> <span class="o">=</span> <span class="n">build_tree</span><span class="p">(</span><span class="n">false_rows</span><span class="p">)</span>

    <span class="c1"># Return a Question node.</span>
    <span class="c1"># This records the best feature / value to ask at this point,</span>
    <span class="c1"># as well as the branches to follow</span>
    <span class="c1"># dependingo on the answer.</span>
    <span class="k">return</span> <span class="n">best_var_split</span><span class="p">,</span> <span class="n">true_branch</span><span class="p">,</span> <span class="n">false_branch</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">build_tree</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">I13</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">014507766889948148</span>
<span class="n">C20</span> <span class="mi">5840</span><span class="n">adea</span> <span class="mi">0</span><span class="p">.</span><span class="mi">1007317969990627</span>
<span class="n">C22</span> <span class="mi">8</span><span class="n">ec974f4</span> <span class="mi">0</span><span class="p">.</span><span class="mi">35123966942148765</span>
<span class="n">I12</span> <span class="mi">2</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">42603550295857984</span>
<span class="n">C26</span> <span class="n">d14e41ff</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">I5</span> <span class="mi">1782</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">008934190851493162</span>
<span class="n">I7</span> <span class="mi">19</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">013055620095586487</span>
<span class="n">C13</span> <span class="mi">605</span><span class="n">bbc24</span> <span class="mi">0</span><span class="p">.</span><span class="mi">010911706067455007</span>
<span class="n">C26</span> <span class="n">cc7a24ff</span> <span class="mi">0</span><span class="p">.</span><span class="mi">24489795918367355</span>
<span class="n">I12</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">018828690566566025</span>
<span class="n">C22</span> <span class="n">ad3062eb</span> <span class="mi">0</span><span class="p">.</span><span class="mi">12180573839966816</span>
<span class="n">C23</span> <span class="mi">55</span><span class="n">dd3565</span> <span class="mi">0</span><span class="p">.</span><span class="mi">21875</span>
<span class="n">C26</span> <span class="n">f6f86eb4</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">C13</span> <span class="n">e40e52ae</span> <span class="mi">0</span><span class="p">.</span><span class="mi">06946786752305406</span>
<span class="n">C2</span> <span class="mi">207</span><span class="n">b2d81</span> <span class="mi">0</span><span class="p">.</span><span class="mi">085260051966354</span>
<span class="n">C23</span> <span class="mi">32</span><span class="n">c7478e</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0738630368259999</span>
<span class="n">I8</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">22721893491124273</span>
<span class="n">I6</span> <span class="mi">15</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">15333333333333318</span>
<span class="n">C26</span> <span class="n">b4aa4b3d</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">C26</span> <span class="n">c84c4aec</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">C22</span> <span class="mi">8</span><span class="n">ec974f4</span> <span class="mi">0</span><span class="p">.</span><span class="mi">05001017772076438</span>
<span class="n">C1</span> <span class="mi">8</span><span class="n">cf07265</span> <span class="mi">0</span><span class="p">.</span><span class="mi">1115255981476716</span>
<span class="n">I11</span> <span class="mi">8</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">11165121373060899</span>
<span class="n">C26</span> <span class="n">bb4e2505</span> <span class="mi">0</span><span class="p">.</span><span class="mi">13265306122448978</span>
<span class="n">C26</span> <span class="n">f159b6cb</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">I6</span> <span class="mi">19</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">31604938271604943</span>
<span class="n">C24</span> <span class="n">b34f3128</span> <span class="mi">0</span><span class="p">.</span><span class="mi">31999999999999984</span>
<span class="n">I12</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span> <span class="mi">0</span><span class="p">.</span><span class="mi">01674185695113256</span>
<span class="n">C19</span> <span class="mi">0</span><span class="n">ec8d23c</span> <span class="mi">0</span><span class="p">.</span><span class="mi">037680719462679674</span>
<span class="n">C22</span> <span class="n">ad3062eb</span> <span class="mi">0</span><span class="p">.</span><span class="mi">15277777777777787</span>
<span class="n">C26</span> <span class="n">eb9a9610</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span>
<span class="n">C25</span> <span class="mi">001</span><span class="n">f3601</span> <span class="mi">0</span><span class="p">.</span><span class="mi">48</span>





<span class="p">((</span><span class="s1">&#39;I13&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
 <span class="p">((</span><span class="s1">&#39;C20&#39;</span><span class="p">,</span> <span class="s1">&#39;5840adea&#39;</span><span class="p">),</span>
  <span class="p">((</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span> <span class="s1">&#39;8ec974f4&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span>
  <span class="p">((</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)),</span>
 <span class="p">((</span><span class="s1">&#39;I5&#39;</span><span class="p">,</span> <span class="mi">1782</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
  <span class="p">((</span><span class="s1">&#39;I7&#39;</span><span class="p">,</span> <span class="mi">19</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
   <span class="p">((</span><span class="s1">&#39;C13&#39;</span><span class="p">,</span> <span class="s1">&#39;605bbc24&#39;</span><span class="p">),</span>
    <span class="p">((</span><span class="s1">&#39;C26&#39;</span><span class="p">,</span> <span class="s1">&#39;cc7a24ff&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span>
    <span class="p">((</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
     <span class="p">((</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span> <span class="s1">&#39;ad3062eb&#39;</span><span class="p">),</span> <span class="p">((</span><span class="s1">&#39;C23&#39;</span><span class="p">,</span> <span class="s1">&#39;55dd3565&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span>
     <span class="p">((</span><span class="s1">&#39;C13&#39;</span><span class="p">,</span> <span class="s1">&#39;e40e52ae&#39;</span><span class="p">),</span>
      <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
      <span class="p">((</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span> <span class="s1">&#39;207b2d81&#39;</span><span class="p">),</span>
       <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
       <span class="p">((</span><span class="s1">&#39;C23&#39;</span><span class="p">,</span> <span class="s1">&#39;32c7478e&#39;</span><span class="p">),</span>
        <span class="p">((</span><span class="s1">&#39;I8&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="p">((</span><span class="s1">&#39;I6&#39;</span><span class="p">,</span> <span class="mi">15</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)),</span>
        <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">))))),</span>
   <span class="p">((</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span> <span class="s1">&#39;8ec974f4&#39;</span><span class="p">),</span>
    <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">((</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="s1">&#39;8cf07265&#39;</span><span class="p">),</span>
     <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span>
     <span class="p">((</span><span class="s1">&#39;I11&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
      <span class="p">((</span><span class="s1">&#39;C26&#39;</span><span class="p">,</span> <span class="s1">&#39;bb4e2505&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">),</span>
      <span class="p">((</span><span class="s1">&#39;I6&#39;</span><span class="p">,</span> <span class="mi">19</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="p">((</span><span class="s1">&#39;C24&#39;</span><span class="p">,</span> <span class="s1">&#39;b34f3128&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)))))),</span>
  <span class="p">((</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">.</span><span class="mi">0</span><span class="p">),</span>
   <span class="p">((</span><span class="s1">&#39;C19&#39;</span><span class="p">,</span> <span class="s1">&#39;0ec8d23c&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="p">((</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span> <span class="s1">&#39;ad3062eb&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)),</span>
   <span class="p">((</span><span class="s1">&#39;C25&#39;</span><span class="p">,</span> <span class="s1">&#39;001f3601&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">))))</span>
</pre></div>


<p><strong>Gradient Boost</strong></p>
<p>We have shown above how to fit a single decision tree. As mentioned, single trees can frequently overfit the data - and generally don't have the best performance. For this reason a common method to use is gradient boost, where we iteratively fit additional trees based on the residual error of the last tree - in this way it is a sequential model. The theory behind this approach is to focus and improve on the 'difficult' datapoints to learn by our current model. We then proceed to iteratively develop trees using the residual error to improve the performance compared to a combination of all previous trees. </p>
<p>Utlimately, by sequentially building trees we have a well fit model. There are a couple of caveats to a gradient boosting approach that should be known prior to implementation and methods to reduce potential error: 
 - Can be prone to over-fitting: As we are sequentially building a model, the model will fine tune towards more niche datapoints and can become over-fit when running the created series of trees on the test set. 
 - Can take a long time to generate given the sequential nature of building trees and depth of each tree
 - In general, have higher performance as compared to a random forest approach with the same number of trees and tree dpeth</p>
<p>The gradient boost algorithm follows the routine listed below: </p>
<ol>
<li>Initialize the model with a constant value: $$F_0(x) = argmin \sum{i = 1}^{n} L(y_i, \gamma)$$ For binary classification we use the log loss probability function as our loss function $$L = y_i * log(p_i) + (1-y_i) * log(1-p_i)$$ For the first initialization we can compute the log-odds as $$log odds = \frac{# of true observations}{# of false observations}$$ in order to map this value into a probability we apply the logistic function $$probability = \frac{e^{-log-odds}}{1+e^{-log-odds}}$$ to get probability values. The model will then be initialized with the same value for all n data-points</li>
<li>Start a loop iterating the number of desired trees desired for gradient boost<ul>
<li>Compute the pseudo-residuals using the following equation: $$\frac{dL}{dF} = \frac{y_i - (1-y_i)<em>e^{y_i}}{1+e^{y_i}}$$ Using the log-loss function this equation equals the observed - predicted values. </em>*<em> We use observed - predicted as it is the first derivative of our loss function defined above: $$\frac{dL}{dF} = \frac{y_i - (1-y_i)</em>e^{y_i}}{1+e^{y_i}} = \frac{y_i * (1+e^{-y_i})}{1+e^{-y_i}} - \frac{1}{1+e^{y_i}}= y_i - p$$</li>
<li>Fit a tree using the pseudo-residuals as the target variable. </li>
<li>In our log-loss scenario, the output values at the leaf node for this second tree are defined using the following equation: $$\gamma_m = argmin \sum{i = 1}^{n} L(y, F_{m-1}(x_i) + \gamma h_m(x_i))$$ Freidman suggested that rather than computing a gamma value for the entire tree, it is more optimal to compute a gamma for each leaf node - this method is more frequently called TreeBoost. Implementing TreeBoost we get the following value at each leaf: $$\gamma_{jm} = Leaf-Node Value = \frac{\sum Residual_i}{\sum {Previous Probability_i * (1-Previous Probability_i)}$$ We cannot add the previous and the residual because the first is in terms of probabilty and the second is in terms of log odds</li>
</ul>
</li>
<li>Update the model using the leaf node value and a learning rate $\alpha$: $log-odds prediction = previous prediction + \alpha * leaf node value$ Above the probability is defined using the logistic regression equation. Implementation of the algorithm can be done using logistic regression or exponential</li>
<li>Iterate the loop building additional trees based on the new pseudo-residual values</li>
</ol>
<p>This implimentation follows Friedman's 'Algorithm 1' routine as noted in the article 'Greedy Function Approximation: A Gradient Boosting Machine'. [Friedman, J. (1999). Greedy Function Approximation: A Gradient Boosting Machine. Stanford: Stanford University.] Note in the implementation below the workflow is simplified by using the decision tree regressor and working in probabilities rather than log-odds and probabilities. </p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">TOY_FILE</span> <span class="o">=</span> <span class="s2">&quot;./data/train.tiny.csv&quot;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">TOY_FILE</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Id&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">train_error</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_error</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Assemble features and labels</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s1">&#39;Label&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">12</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Learning Rate</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># Copy Labels over to dataframe</span>
<span class="n">residual_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">])</span>
<span class="c1"># Compute log-odds based on proportion of true/false</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">values</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>
<span class="c1"># Convert log-odds to probability using logistic function</span>
<span class="n">prob</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">F</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">F</span><span class="p">))</span>
<span class="n">prob_test</span> <span class="o">=</span> <span class="n">prob</span><span class="c1">#np.exp(np.log(len(y_test.values == 1) / len(y_test.values == 0))) / (1 + np.exp(np.log(len(y_test.values == 1) / len(y_test.values == 0))))</span>
<span class="c1"># Copy over prediction and residuals</span>
<span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;residual&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">-</span> <span class="n">prob</span>
<span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">dtr</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="c1"># set desired value to residual</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;residual&#39;</span><span class="p">]</span>
    <span class="c1"># fit the decision tree</span>
    <span class="n">dtr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># copmute probability as the prior probability + learning-rate * prediction</span>
    <span class="n">prob</span> <span class="o">=</span> <span class="n">prob</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dtr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
    <span class="n">prob_test</span> <span class="o">=</span> <span class="n">prob_test</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">dtr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="c1"># update residual_df dataframe</span>
    <span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;residual&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">prob</span>
    <span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;prob&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">prob</span>
    <span class="c1"># print score based on log-loss</span>
    <span class="n">train_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_loss</span><span class="p">(</span><span class="n">residual_df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">],</span> <span class="n">prob</span><span class="p">))</span>
    <span class="n">test_error</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prob_test</span><span class="p">))</span>
<span class="c1">#     print(&quot;Train Error: &quot; + str(log_loss(residual_df[&#39;Label&#39;], prob)))</span>
<span class="c1">#     print(&quot;Test Error: &quot; + str(log_loss(y_test, prob_test)))</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Train&#39;</span><span class="p">:</span> <span class="n">train_error</span><span class="p">,</span>
                      <span class="s1">&#39;Test&#39;</span><span class="p">:</span> <span class="n">test_error</span><span class="p">})</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">error</span><span class="p">[</span><span class="s1">&#39;Train&#39;</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Train Error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">error</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">error</span><span class="p">[</span><span class="s1">&#39;Test&#39;</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Test Error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Log Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Loss for Gradient Boost Algorithm&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Text(0.5,1,&#39;Loss for Gradient Boost Algorithm&#39;)</span>
</pre></div>


<table><tr>
    <td> <img src="images/clickthrough/output_8_1.png" alt="Drawing" style="width: 750px;"/> </td>
</tr></table>

<h3>Data Gathering and EDA</h3>
<p>Download and unpack the dataset</p>
<div class="highlight"><pre><span></span><span class="c1"># !curl -L -o criteo.tar.gz https://s3-eu-west-1.amazonaws.com/kaggle-display-advertising-challenge-dataset/dac.tar.gz</span>
</pre></div>


<div class="highlight"><pre><span></span>  <span class="c">% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span>
                                 <span class="n">Dload</span>  <span class="s">Upload</span>   <span class="s">Total</span>   <span class="s">Spent</span>    <span class="s">Left</span>  <span class="s">Speed</span>
  <span class="n">4</span> <span class="s">4364M</span>    <span class="s">4</span>  <span class="s">217M</span>    <span class="s">0</span>     <span class="s">0</span>   <span class="s">349k</span>      <span class="s">0</span>  <span class="s">3:33:15</span>  <span class="s">0:10:38</span>  <span class="s">3:22:37</span>  <span class="s">327k^C</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># !mkdir -p data</span>
<span class="c1"># !tar -xvzf criteo.tar.gz -C ./data</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">tar</span><span class="o">:</span> <span class="n">Ignoring</span> <span class="n">unknown</span> <span class="n">extended</span> <span class="n">header</span> <span class="n">keyword</span> <span class="err">`</span><span class="n">SCHILY</span><span class="o">.</span><span class="na">dev</span><span class="s1">&#39;</span>
<span class="s1">tar: Ignoring unknown extended header keyword `SCHILY.ino&#39;</span>
<span class="n">tar</span><span class="o">:</span> <span class="n">Ignoring</span> <span class="n">unknown</span> <span class="n">extended</span> <span class="n">header</span> <span class="n">keyword</span> <span class="err">`</span><span class="n">SCHILY</span><span class="o">.</span><span class="na">nlink</span><span class="s1">&#39;</span>
<span class="s1">readme.txt</span>
<span class="s1">tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime&#39;</span>
<span class="n">tar</span><span class="o">:</span> <span class="n">Ignoring</span> <span class="n">unknown</span> <span class="n">extended</span> <span class="n">header</span> <span class="n">keyword</span> <span class="err">`</span><span class="n">SCHILY</span><span class="o">.</span><span class="na">dev</span><span class="s1">&#39;</span>
<span class="s1">tar: Ignoring unknown extended header keyword `SCHILY.ino&#39;</span>
<span class="n">tar</span><span class="o">:</span> <span class="n">Ignoring</span> <span class="n">unknown</span> <span class="n">extended</span> <span class="n">header</span> <span class="n">keyword</span> <span class="err">`</span><span class="n">SCHILY</span><span class="o">.</span><span class="na">nlink</span><span class="err">&#39;</span>
<span class="n">test</span><span class="o">.</span><span class="na">txt</span>

<span class="n">gzip</span><span class="o">:</span> <span class="n">stdin</span><span class="o">:</span> <span class="n">unexpected</span> <span class="n">end</span> <span class="n">of</span> <span class="n">file</span>
<span class="n">tar</span><span class="o">:</span> <span class="n">Unexpected</span> <span class="n">EOF</span> <span class="k">in</span> <span class="n">archive</span>
<span class="n">tar</span><span class="o">:</span> <span class="n">Error</span> <span class="k">is</span> <span class="n">not</span> <span class="n">recoverable</span><span class="o">:</span> <span class="n">exiting</span> <span class="n">now</span>
</pre></div>


<p>Inspect the file that contains the training data</p>
<div class="highlight"><pre><span></span><span class="n">TRAIN_FILE</span><span class="o">=</span><span class="s2">&quot;./data/train.txt&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First line: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="err">!</span><span class="n">head</span> <span class="o">-</span><span class="n">n</span> <span class="mi">5</span> <span class="err">$</span><span class="n">TRAIN_FILE</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Number of columns: &quot;</span><span class="p">)</span>
<span class="err">!</span><span class="n">head</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1</span> <span class="err">$</span><span class="n">TRAIN_FILE</span> <span class="o">|</span> <span class="n">wc</span> <span class="o">-</span><span class="n">w</span>

<span class="c1"># print(&quot;\nNumber of rows: &quot;)</span>
<span class="c1"># !wc -l &lt; $TRAIN_FILE</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">First</span> <span class="n">line</span><span class="p">:</span>

<span class="mi">0</span>   <span class="mi">1</span>   <span class="mi">1</span>   <span class="mi">5</span>   <span class="mi">0</span>   <span class="mi">1382</span>    <span class="mi">4</span>   <span class="mi">15</span>  <span class="mi">2</span>   <span class="mi">181</span> <span class="mi">1</span>   <span class="mi">2</span>       <span class="mi">2</span>   <span class="mi">68</span><span class="n">fd1e64</span>    <span class="mi">80</span><span class="n">e26c9b</span>    <span class="n">fb936136</span>    <span class="mi">7</span><span class="n">b4723c4</span>    <span class="mi">25</span><span class="n">c83c98</span>    <span class="mi">7</span><span class="n">e0ccccf</span>    <span class="n">de7995b8</span>    <span class="mi">1</span><span class="n">f89b562</span>    <span class="n">a73ee510</span>    <span class="n">a8cd5504</span>    <span class="n">b2cb9c98</span>    <span class="mi">37</span><span class="n">c9c164</span>    <span class="mi">2824</span><span class="n">a5f6</span>    <span class="mi">1</span><span class="n">adce6ef</span>    <span class="mi">8</span><span class="n">ba8b39a</span>    <span class="mi">891</span><span class="n">b62e7</span>    <span class="n">e5ba7672</span>    <span class="n">f54016b9</span>    <span class="mi">21</span><span class="n">ddcdc9</span>    <span class="n">b1252a9d</span>    <span class="mi">07</span><span class="n">b5194c</span>        <span class="mi">3</span><span class="n">a171ecb</span>    <span class="n">c5c50484</span>    <span class="n">e8b83407</span>    <span class="mi">9727</span><span class="n">dd16</span>
<span class="mi">0</span>   <span class="mi">2</span>   <span class="mi">0</span>   <span class="mi">44</span>  <span class="mi">1</span>   <span class="mi">102</span> <span class="mi">8</span>   <span class="mi">2</span>   <span class="mi">2</span>   <span class="mi">4</span>   <span class="mi">1</span>   <span class="mi">1</span>       <span class="mi">4</span>   <span class="mi">68</span><span class="n">fd1e64</span>    <span class="n">f0cf0024</span>    <span class="mi">6</span><span class="n">f67f7e5</span>    <span class="mi">41274</span><span class="n">cd7</span>    <span class="mi">25</span><span class="n">c83c98</span>    <span class="n">fe6b92e5</span>    <span class="mi">922</span><span class="n">afcc0</span>    <span class="mi">0</span><span class="n">b153874</span>    <span class="n">a73ee510</span>    <span class="mi">2</span><span class="n">b53e5fb</span>    <span class="mi">4</span><span class="n">f1b46f3</span>    <span class="mi">623049</span><span class="n">e6</span>    <span class="n">d7020589</span>    <span class="n">b28479f6</span>    <span class="n">e6c5b5cd</span>    <span class="n">c92f3b61</span>    <span class="mi">07</span><span class="n">c540c4</span>    <span class="n">b04e4670</span>    <span class="mi">21</span><span class="n">ddcdc9</span>    <span class="mi">5840</span><span class="n">adea</span>    <span class="mi">60</span><span class="n">f6221e</span>        <span class="mi">3</span><span class="n">a171ecb</span>    <span class="mi">43</span><span class="n">f13e8b</span>    <span class="n">e8b83407</span>    <span class="mi">731</span><span class="n">c3655</span>
<span class="mi">0</span>   <span class="mi">2</span>   <span class="mi">0</span>   <span class="mi">1</span>   <span class="mi">14</span>  <span class="mi">767</span> <span class="mi">89</span>  <span class="mi">4</span>   <span class="mi">2</span>   <span class="mi">245</span> <span class="mi">1</span>   <span class="mi">3</span>   <span class="mi">3</span>   <span class="mi">45</span>  <span class="mi">287</span><span class="n">e684f</span>    <span class="mi">0</span><span class="n">a519c5c</span>    <span class="mi">02</span><span class="n">cf9876</span>    <span class="n">c18be181</span>    <span class="mi">25</span><span class="n">c83c98</span>    <span class="mi">7</span><span class="n">e0ccccf</span>    <span class="n">c78204a1</span>    <span class="mi">0</span><span class="n">b153874</span>    <span class="n">a73ee510</span>    <span class="mi">3</span><span class="n">b08e48b</span>    <span class="mi">5</span><span class="n">f5e6091</span>    <span class="mi">8</span><span class="n">fe001f4</span>    <span class="n">aa655a2f</span>    <span class="mi">07</span><span class="n">d13a8f</span>    <span class="mi">6</span><span class="n">dc710ed</span>    <span class="mi">36103458</span>    <span class="mi">8</span><span class="n">efede7f</span>    <span class="mi">3412118</span><span class="n">d</span>            <span class="n">e587c466</span>    <span class="n">ad3062eb</span>    <span class="mi">3</span><span class="n">a171ecb</span>    <span class="mi">3</span><span class="n">b183c5c</span>        
<span class="mi">0</span>       <span class="mi">893</span>         <span class="mi">4392</span>        <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">0</span>       <span class="mi">0</span>           <span class="mi">68</span><span class="n">fd1e64</span>    <span class="mi">2</span><span class="n">c16a946</span>    <span class="n">a9a87e68</span>    <span class="mi">2</span><span class="n">e17d6f6</span>    <span class="mi">25</span><span class="n">c83c98</span>    <span class="n">fe6b92e5</span>    <span class="mi">2</span><span class="n">e8a689b</span>    <span class="mi">0</span><span class="n">b153874</span>    <span class="n">a73ee510</span>    <span class="n">efea433b</span>    <span class="n">e51ddf94</span>    <span class="n">a30567ca</span>    <span class="mi">3516</span><span class="n">f6e6</span>    <span class="mi">07</span><span class="n">d13a8f</span>    <span class="mi">18231224</span>    <span class="mi">52</span><span class="n">b8680f</span>    <span class="mi">1</span><span class="n">e88c74f</span>    <span class="mi">74</span><span class="n">ef3502</span>            <span class="mi">6</span><span class="n">b3a5ca6</span>        <span class="mi">3</span><span class="n">a171ecb</span>    <span class="mi">9117</span><span class="n">a34a</span>        
<span class="mi">0</span>   <span class="mi">3</span>   <span class="o">-</span><span class="mi">1</span>      <span class="mi">0</span>   <span class="mi">2</span>   <span class="mi">0</span>   <span class="mi">3</span>   <span class="mi">0</span>   <span class="mi">0</span>   <span class="mi">1</span>   <span class="mi">1</span>       <span class="mi">0</span>   <span class="mi">8</span><span class="n">cf07265</span>    <span class="n">ae46a29d</span>    <span class="n">c81688bb</span>    <span class="n">f922efad</span>    <span class="mi">25</span><span class="n">c83c98</span>    <span class="mi">13718</span><span class="n">bbd</span>    <span class="n">ad9fa255</span>    <span class="mi">0</span><span class="n">b153874</span>    <span class="n">a73ee510</span>    <span class="mi">5282</span><span class="n">c137</span>    <span class="n">e5d8af57</span>    <span class="mi">66</span><span class="n">a76a26</span>    <span class="n">f06c53ac</span>    <span class="mi">1</span><span class="n">adce6ef</span>    <span class="mi">8</span><span class="n">ff4b403</span>    <span class="mi">01</span><span class="n">adbab4</span>    <span class="mi">1</span><span class="n">e88c74f</span>    <span class="mi">26</span><span class="n">b3c7a7</span>            <span class="mi">21</span><span class="n">c9516a</span>        <span class="mi">32</span><span class="n">c7478e</span>    <span class="n">b34f3128</span>

<span class="nb">Number</span> <span class="k">of</span> <span class="n">columns</span><span class="p">:</span> 
<span class="mi">38</span>
</pre></div>


<p>Create RDDs from the parsed input files and <em>cache</em> them so that the parsing has to occur only once.</p>
<div class="highlight"><pre><span></span><span class="c1"># imports</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">types</span>
<span class="kn">import</span> <span class="nn">pyspark.sql</span>
<span class="kn">import</span> <span class="nn">pyspark.sql.functions</span>

<span class="c1"># start Spark Session</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="n">app_name</span> <span class="o">=</span> <span class="s2">&quot;hw3_notebook&quot;</span>
<span class="n">master</span> <span class="o">=</span> <span class="s2">&quot;local[*]&quot;</span>
<span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span>\
        <span class="o">.</span><span class="n">builder</span>\
        <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="n">app_name</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">master</span><span class="p">(</span><span class="n">master</span><span class="p">)</span>\
        <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sparkContext</span>

<span class="c1"># create RDDs</span>
<span class="n">trainRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;./data/train.txt&quot;</span><span class="p">)</span>
<span class="n">testRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s2">&quot;./data/test.txt&quot;</span><span class="p">)</span>
<span class="n">toytrainRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s1">&#39;./data/toy_train.txt&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># store path to notebook</span>
<span class="n">PWD</span> <span class="o">=</span> <span class="err">!</span><span class="n">pwd</span>
<span class="n">PWD</span> <span class="o">=</span> <span class="n">PWD</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;I1&#39;</span><span class="p">,</span><span class="s1">&#39;I2&#39;</span><span class="p">,</span><span class="s1">&#39;I3&#39;</span><span class="p">,</span><span class="s1">&#39;I4&#39;</span><span class="p">,</span><span class="s1">&#39;I5&#39;</span><span class="p">,</span><span class="s1">&#39;I6&#39;</span><span class="p">,</span><span class="s1">&#39;I7&#39;</span><span class="p">,</span><span class="s1">&#39;I8&#39;</span><span class="p">,</span><span class="s1">&#39;I9&#39;</span><span class="p">,</span><span class="s1">&#39;I10&#39;</span><span class="p">,</span><span class="s1">&#39;I11&#39;</span><span class="p">,</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span><span class="s1">&#39;I13&#39;</span><span class="p">,</span>
          <span class="s1">&#39;C1&#39;</span><span class="p">,</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span><span class="s1">&#39;C3&#39;</span><span class="p">,</span><span class="s1">&#39;C4&#39;</span><span class="p">,</span><span class="s1">&#39;C5&#39;</span><span class="p">,</span><span class="s1">&#39;C6&#39;</span><span class="p">,</span><span class="s1">&#39;C7&#39;</span><span class="p">,</span><span class="s1">&#39;C8&#39;</span><span class="p">,</span><span class="s1">&#39;C9&#39;</span><span class="p">,</span><span class="s1">&#39;C10&#39;</span><span class="p">,</span><span class="s1">&#39;C11&#39;</span><span class="p">,</span><span class="s1">&#39;C12&#39;</span><span class="p">,</span><span class="s1">&#39;C13&#39;</span><span class="p">,</span><span class="s1">&#39;C14&#39;</span><span class="p">,</span>
          <span class="s1">&#39;C15&#39;</span><span class="p">,</span><span class="s1">&#39;C16&#39;</span><span class="p">,</span><span class="s1">&#39;C17&#39;</span><span class="p">,</span><span class="s1">&#39;C18&#39;</span><span class="p">,</span><span class="s1">&#39;C19&#39;</span><span class="p">,</span><span class="s1">&#39;C20&#39;</span><span class="p">,</span><span class="s1">&#39;C21&#39;</span><span class="p">,</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span><span class="s1">&#39;C23&#39;</span><span class="p">,</span><span class="s1">&#39;C24&#39;</span><span class="p">,</span><span class="s1">&#39;C25&#39;</span><span class="p">,</span><span class="s1">&#39;C26&#39;</span><span class="p">,</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span>

<span class="c1"># Generate 80/20 (pseudo)random train/test split </span>
<span class="n">trainRDD</span><span class="p">,</span> <span class="n">heldOutRDD</span> <span class="o">=</span> <span class="n">fullRDD</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.2</span><span class="p">],</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;... leaving out </span><span class="si">{</span><span class="n">heldOutRDD</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">}</span><span class="s2"> records for evaluation and assigning </span><span class="si">{</span><span class="n">trainRDD</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">}</span><span class="s2"> records for training.&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">toyRDD</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s1">&#39;data/toy1000.txt&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of records in toy data: </span><span class="si">{</span><span class="n">toyRDD</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="si">}</span><span class="s2"> ...&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">toytrainRDD</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">[&#39;0\t1.0\t1\t5.0\t0.0\t1382.0\t4.0\t15.0\t2.0\t181.0\t1.0\t2.0\t\t2.0\t68fd1e64\t80e26c9b\tfb936136\t7b4723c4\t25c83c98\t7e0ccccf\tde7995b8\t1f89b562\ta73ee510\ta8cd5504\tb2cb9c98\t37c9c164\t2824a5f6\t1adce6ef\t8ba8b39a\t891b62e7\te5ba7672\tf54016b9\t21ddcdc9\tb1252a9d\t07b5194c\t\t3a171ecb\tc5c50484\te8b83407\t9727dd16&#39;]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">parse_feature</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fields</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fields</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="c1"># remove empty features introduced by extra tabs</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">parse_empty</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">label</span><span class="p">,</span> <span class="n">features</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">fields</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">fields</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="c1"># remove empty features introduced by extra tabs</span>
    <span class="k">if</span> <span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
        <span class="k">yield</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># helper functions</span>
<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Map line --&gt; tuple of (features, label)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">features</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="n">fields</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">fields</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">edit_data_types</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Map tuple of (features, label) --&gt; tuple of (formated features, label)</span>

<span class="sd">    * &#39;&#39; is replaced with &#39;null&#39;</span>
<span class="sd">    * numerical fields are converted to integers</span>
<span class="sd">    * make label column numeric</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">formated_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">formated_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;null&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">13</span><span class="p">:</span>
                <span class="n">formated_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">value</span><span class="p">))</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="n">formated_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">formated_features</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">label</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">trainRDDCached</span> <span class="o">=</span> <span class="n">trainRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parse</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="n">testRDDCached</span> <span class="o">=</span> <span class="n">testRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parse</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
<span class="c1"># Parsing, making &#39;&#39; as np.nan and converting numerical features and output label to int</span>
<span class="c1"># trainRDDCached = trainRDD.map(parse).map(edit_data_types).cache()</span>
<span class="n">toyRDDCached</span> <span class="o">=</span> <span class="n">toyRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parse</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">edit_data_types</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
</pre></div>


<p>We would expect there to be a class imbalance with many more unclicked ads than clicked ads, but let's see how extreme it is. We can perform this counting with a <em>map</em> operation that emits the value of the label and a count of 1 and a <em>reduce</em> operation that sums the count. </p>
<div class="highlight"><pre><span></span><span class="n">trainRDDCached</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">[(0, 34095179), (1, 11745438)]</span>
</pre></div>


<p>So approximately 74.4% of the data is the negative class.</p>
<div class="highlight"><pre><span></span><span class="n">col</span> <span class="o">=</span> <span class="err">!</span><span class="n">head</span> <span class="o">-</span><span class="n">n</span> <span class="mi">1</span> <span class="err">$</span><span class="n">TRAIN_FILE</span> <span class="o">|</span> <span class="n">wc</span> <span class="o">-</span><span class="n">w</span>
<span class="n">total</span> <span class="o">=</span> <span class="err">!</span><span class="n">wc</span> <span class="o">-</span><span class="n">l</span> <span class="o">&lt;</span> <span class="err">$</span><span class="n">TRAIN_FILE</span>
<span class="n">total</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">num_unique</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">num_nan</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">39</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">RDD</span> <span class="o">=</span> <span class="n">toytrainRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">parse_feature</span><span class="p">)</span><span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">:</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
    <span class="n">unique</span> <span class="o">=</span> <span class="n">RDD</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">num_unique</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">unique</span><span class="p">)</span>
    <span class="n">blank</span> <span class="o">=</span> <span class="n">toytrainRDD</span><span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="n">parse_empty</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">num_nan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">blank</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique values in column &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">unique</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; Number of empty values in column: &#39;</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="n">blank</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Unique values in column 1: 344 Number of empty values in column: 0</span>
<span class="err">Unique values in column 2: 148 Number of empty values in column: 449</span>
<span class="err">Unique values in column 3: 56 Number of empty values in column: 420</span>
<span class="err">Unique values in column 4: 1431 Number of empty values in column: 93</span>
<span class="err">Unique values in column 5: 408 Number of empty values in column: 493</span>
<span class="err">Unique values in column 6: 119 Number of empty values in column: 93</span>
<span class="err">Unique values in column 7: 56 Number of empty values in column: 2</span>
<span class="err">Unique values in column 8: 422 Number of empty values in column: 93</span>
<span class="err">Unique values in column 9: 6 Number of empty values in column: 889</span>
<span class="err">Unique values in column 10: 31 Number of empty values in column: 93</span>
<span class="err">Unique values in column 11: 16 Number of empty values in column: 1554</span>
<span class="err">Unique values in column 12: 84 Number of empty values in column: 420</span>
<span class="err">Unique values in column 13: 79 Number of empty values in column: 0</span>
<span class="err">Unique values in column 14: 252 Number of empty values in column: 0</span>
<span class="err">Unique values in column 15: 1293 Number of empty values in column: 66</span>
<span class="err">Unique values in column 16: 1043 Number of empty values in column: 66</span>
<span class="err">Unique values in column 17: 30 Number of empty values in column: 0</span>
<span class="err">Unique values in column 18: 7 Number of empty values in column: 251</span>
<span class="err">Unique values in column 19: 1164 Number of empty values in column: 0</span>
<span class="err">Unique values in column 20: 39 Number of empty values in column: 0</span>
<span class="err">Unique values in column 21: 2 Number of empty values in column: 0</span>
<span class="err">Unique values in column 22: 908 Number of empty values in column: 0</span>
<span class="err">Unique values in column 23: 926 Number of empty values in column: 0</span>
<span class="err">Unique values in column 24: 1239 Number of empty values in column: 66</span>
<span class="err">Unique values in column 25: 824 Number of empty values in column: 0</span>
<span class="err">Unique values in column 26: 20 Number of empty values in column: 0</span>
<span class="err">Unique values in column 27: 819 Number of empty values in column: 0</span>
<span class="err">Unique values in column 28: 1159 Number of empty values in column: 66</span>
<span class="err">Unique values in column 29: 9 Number of empty values in column: 0</span>
<span class="err">Unique values in column 30: 534 Number of empty values in column: 0</span>
<span class="err">Unique values in column 31: 201 Number of empty values in column: 965</span>
<span class="err">Unique values in column 32: 4 Number of empty values in column: 965</span>
<span class="err">Unique values in column 33: 1204 Number of empty values in column: 66</span>
<span class="err">Unique values in column 34: 7 Number of empty values in column: 1631</span>
<span class="err">Unique values in column 35: 12 Number of empty values in column: 0</span>
<span class="err">Unique values in column 36: 729 Number of empty values in column: 66</span>
<span class="err">Unique values in column 37: 33 Number of empty values in column: 965</span>
<span class="err">Unique values in column 38: 554 Number of empty values in column: 965</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># helper function &#39;null&#39; to np.nan for pandas df </span>
<span class="k">def</span> <span class="nf">null_to_nan</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    converts &quot;null&quot; to np.nan in RDD</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">formated_features</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">features</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;null&#39;</span><span class="p">:</span>
            <span class="n">formated_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">formated_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">formated_features</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

<span class="c1"># put the toy RDD into a pandas dataframe for EDA charting</span>
<span class="n">trainRDDtoPandas</span> <span class="o">=</span> <span class="n">toyRDDCached</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">null_to_nan</span><span class="p">)</span> \
                                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span> \
                                <span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="n">FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;I1&#39;</span><span class="p">,</span><span class="s1">&#39;I2&#39;</span><span class="p">,</span><span class="s1">&#39;I3&#39;</span><span class="p">,</span><span class="s1">&#39;I4&#39;</span><span class="p">,</span><span class="s1">&#39;I5&#39;</span><span class="p">,</span><span class="s1">&#39;I6&#39;</span><span class="p">,</span><span class="s1">&#39;I7&#39;</span><span class="p">,</span><span class="s1">&#39;I8&#39;</span><span class="p">,</span><span class="s1">&#39;I9&#39;</span><span class="p">,</span><span class="s1">&#39;I10&#39;</span><span class="p">,</span><span class="s1">&#39;I11&#39;</span><span class="p">,</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span><span class="s1">&#39;I13&#39;</span><span class="p">,</span>
          <span class="s1">&#39;C1&#39;</span><span class="p">,</span><span class="s1">&#39;C2&#39;</span><span class="p">,</span><span class="s1">&#39;C3&#39;</span><span class="p">,</span><span class="s1">&#39;C4&#39;</span><span class="p">,</span><span class="s1">&#39;C5&#39;</span><span class="p">,</span><span class="s1">&#39;C6&#39;</span><span class="p">,</span><span class="s1">&#39;C7&#39;</span><span class="p">,</span><span class="s1">&#39;C8&#39;</span><span class="p">,</span><span class="s1">&#39;C9&#39;</span><span class="p">,</span><span class="s1">&#39;C10&#39;</span><span class="p">,</span><span class="s1">&#39;C11&#39;</span><span class="p">,</span><span class="s1">&#39;C12&#39;</span><span class="p">,</span><span class="s1">&#39;C13&#39;</span><span class="p">,</span><span class="s1">&#39;C14&#39;</span><span class="p">,</span>
          <span class="s1">&#39;C15&#39;</span><span class="p">,</span><span class="s1">&#39;C16&#39;</span><span class="p">,</span><span class="s1">&#39;C17&#39;</span><span class="p">,</span><span class="s1">&#39;C18&#39;</span><span class="p">,</span><span class="s1">&#39;C19&#39;</span><span class="p">,</span><span class="s1">&#39;C20&#39;</span><span class="p">,</span><span class="s1">&#39;C21&#39;</span><span class="p">,</span><span class="s1">&#39;C22&#39;</span><span class="p">,</span><span class="s1">&#39;C23&#39;</span><span class="p">,</span><span class="s1">&#39;C24&#39;</span><span class="p">,</span><span class="s1">&#39;C25&#39;</span><span class="p">,</span><span class="s1">&#39;C26&#39;</span><span class="p">,</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span>

<span class="n">toy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">trainRDDtoPandas</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">FIELDS</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">toy_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>I10</th>
      <th>...</th>
      <th>C18</th>
      <th>C19</th>
      <th>C20</th>
      <th>C21</th>
      <th>C22</th>
      <th>C23</th>
      <th>C24</th>
      <th>C25</th>
      <th>C26</th>
      <th>Label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>478.0</td>
      <td>13.0</td>
      <td>nan</td>
      <td>3396.0</td>
      <td>194.0</td>
      <td>11.0</td>
      <td>13.0</td>
      <td>312.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>395856b0</td>
      <td>21ddcdc9</td>
      <td>b1252a9d</td>
      <td>8e4884c0</td>
      <td>nan</td>
      <td>423fab69</td>
      <td>b936bfbe</td>
      <td>001f3601</td>
      <td>f2fc1d6e</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2.0</td>
      <td>0.0</td>
      <td>nan</td>
      <td>nan</td>
      <td>1209.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>526e8765</td>
      <td>nan</td>
      <td>nan</td>
      <td>8b7fb864</td>
      <td>nan</td>
      <td>32c7478e</td>
      <td>45b2acf4</td>
      <td>nan</td>
      <td>nan</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>nan</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>489.0</td>
      <td>66.0</td>
      <td>0.0</td>
      <td>11.0</td>
      <td>8.0</td>
      <td>nan</td>
      <td>...</td>
      <td>8f9b4e88</td>
      <td>nan</td>
      <td>nan</td>
      <td>050a23dc</td>
      <td>nan</td>
      <td>32c7478e</td>
      <td>8a3cfad4</td>
      <td>nan</td>
      <td>nan</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>179.0</td>
      <td>7.0</td>
      <td>8.0</td>
      <td>996.0</td>
      <td>67.0</td>
      <td>6.0</td>
      <td>44.0</td>
      <td>344.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>2804effd</td>
      <td>nan</td>
      <td>nan</td>
      <td>723b4dfd</td>
      <td>nan</td>
      <td>32c7478e</td>
      <td>b34f3128</td>
      <td>nan</td>
      <td>nan</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>2.0</td>
      <td>10.0</td>
      <td>27.0</td>
      <td>1101.0</td>
      <td>29.0</td>
      <td>11.0</td>
      <td>42.0</td>
      <td>241.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>e88ffc9d</td>
      <td>21ddcdc9</td>
      <td>b1252a9d</td>
      <td>dca9a28d</td>
      <td>ad3062eb</td>
      <td>bcdee96c</td>
      <td>3fdb382b</td>
      <td>cb079c2d</td>
      <td>1c2df582</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 40 columns</p>
</div>

<div class="highlight"><pre><span></span><span class="c1"># TOY DATA</span>
<span class="c1"># counting records for each class </span>
<span class="n">count_label_0</span> <span class="o">=</span> <span class="n">toyRDDCached</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">count_label_1</span> <span class="o">=</span> <span class="n">toyRDDCached</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">count_label_0</span> <span class="o">+</span> <span class="n">count_label_1</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">count_label_0</span><span class="o">/</span><span class="n">total</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2"> % of the records have label=0 and </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">count_label_1</span><span class="o">/</span><span class="n">total</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s2"> % have label=1...&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">72.3 % of the records have label=0 and 27.7 % have label=1...</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_pct_nulls_in_column</span><span class="p">(</span><span class="n">dataRDD</span><span class="p">,</span> <span class="n">var_position</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Counts the % nulls in a column </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">null_count</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span> \
                             <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">==</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">total_count</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">null_count</span><span class="o">/</span><span class="n">total_count</span><span class="o">*</span><span class="mi">100</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># TOY DATA</span>
<span class="k">for</span> <span class="n">var_position</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">FIELDS</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">var_position</span> <span class="o">&lt;</span> <span class="mi">39</span><span class="p">:</span>
        <span class="n">null_pct</span> <span class="o">=</span> <span class="n">get_pct_nulls_in_column</span><span class="p">(</span><span class="n">toyRDDCached</span><span class="p">,</span> <span class="n">var_position</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FEATURE </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}% i</span><span class="s2">s null&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">null_pct</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">FEATURE I1: 43.2% is null</span>
<span class="err">FEATURE I2: 0.0% is null</span>
<span class="err">FEATURE I3: 21.3% is null</span>
<span class="err">FEATURE I4: 22.1% is null</span>
<span class="err">FEATURE I5: 2.4% is null</span>
<span class="err">FEATURE I6: 23.0% is null</span>
<span class="err">FEATURE I7: 3.7% is null</span>
<span class="err">FEATURE I8: 0.0% is null</span>
<span class="err">FEATURE I9: 3.7% is null</span>
<span class="err">FEATURE I10: 43.2% is null</span>
<span class="err">FEATURE I11: 3.7% is null</span>
<span class="err">FEATURE I12: 77.4% is null</span>
<span class="err">FEATURE I13: 22.1% is null</span>
<span class="err">FEATURE C1: 0.0% is null</span>
<span class="err">FEATURE C2: 0.0% is null</span>
<span class="err">FEATURE C3: 3.4% is null</span>
<span class="err">FEATURE C4: 3.4% is null</span>
<span class="err">FEATURE C5: 0.0% is null</span>
<span class="err">FEATURE C6: 13.4% is null</span>
<span class="err">FEATURE C7: 0.0% is null</span>
<span class="err">FEATURE C8: 0.0% is null</span>
<span class="err">FEATURE C9: 0.0% is null</span>
<span class="err">FEATURE C10: 0.0% is null</span>
<span class="err">FEATURE C11: 0.0% is null</span>
<span class="err">FEATURE C12: 3.4% is null</span>
<span class="err">FEATURE C13: 0.0% is null</span>
<span class="err">FEATURE C14: 0.0% is null</span>
<span class="err">FEATURE C15: 0.0% is null</span>
<span class="err">FEATURE C16: 3.4% is null</span>
<span class="err">FEATURE C17: 0.0% is null</span>
<span class="err">FEATURE C18: 0.0% is null</span>
<span class="err">FEATURE C19: 42.2% is null</span>
<span class="err">FEATURE C20: 42.2% is null</span>
<span class="err">FEATURE C21: 3.4% is null</span>
<span class="err">FEATURE C22: 74.5% is null</span>
<span class="err">FEATURE C23: 0.0% is null</span>
<span class="err">FEATURE C24: 3.4% is null</span>
<span class="err">FEATURE C25: 42.2% is null</span>
<span class="err">FEATURE C26: 42.2% is null</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># RDD version </span>
<span class="k">def</span> <span class="nf">get_stats</span><span class="p">(</span><span class="n">dataRDD</span><span class="p">,</span> <span class="n">var_position</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get statistics for numeric variables </span>
<span class="sd">    stats: mean, median, variance, min, max </span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">mean</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> 
    <span class="n">variance</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">variance</span><span class="p">()</span> 
    <span class="n">minimum</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> 
    <span class="n">maximum</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">])</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">!=</span> <span class="s1">&#39;null&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> 

    <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">minimum</span><span class="p">,</span> <span class="n">maximum</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># save the means in a dictionary</span>
<span class="n">mean_dict_toy</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">st_dev_dict_toy</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># get summary stats with RDDs</span>
<span class="k">for</span> <span class="n">var_position</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">FIELDS</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">var_position</span> <span class="o">&lt;</span> <span class="mi">13</span><span class="p">:</span>
        <span class="n">mean</span><span class="p">,</span> <span class="n">variance</span><span class="p">,</span> <span class="n">minimum</span><span class="p">,</span> <span class="n">maximum</span> <span class="o">=</span> <span class="n">get_stats</span><span class="p">(</span><span class="n">toyRDDCached</span><span class="p">,</span> <span class="n">var_position</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FEATURE </span><span class="si">{}</span><span class="s2">: </span><span class="se">\t</span><span class="s2"> mean=</span><span class="si">{}</span><span class="s2">, </span><span class="se">\t</span><span class="s2"> variance=</span><span class="si">{}</span><span class="s2">, </span><span class="se">\t</span><span class="s2"> min=</span><span class="si">{}</span><span class="s2">, </span><span class="se">\t</span><span class="s2"> max=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">variance</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">minimum</span><span class="p">,</span> <span class="n">maximum</span><span class="p">))</span>
        <span class="n">mean_dict_toy</span><span class="p">[</span><span class="n">var_position</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean</span>
        <span class="n">st_dev_dict_toy</span><span class="p">[</span><span class="n">var_position</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">FEATURE I1:      mean=3.17,      variance=33.98,     min=0.0,    max=55.0</span>
<span class="err">FEATURE I2:      mean=114.72,    variance=179230.84,     min=-2.0,   max=5123.0</span>
<span class="err">FEATURE I3:      mean=18.78,     variance=2026.69,   min=0.0,    max=648.0</span>
<span class="err">FEATURE I4:      mean=7.43,      variance=86.02,     min=0.0,    max=77.0</span>
<span class="err">FEATURE I5:      mean=18392.77,      variance=4908735552.87,     min=0.0,    max=1002457.0</span>
<span class="err">FEATURE I6:      mean=95.23,     variance=65007.31,      min=0.0,    max=4304.0</span>
<span class="err">FEATURE I7:      mean=17.94,     variance=8794.35,   min=0.0,    max=2614.0</span>
<span class="err">FEATURE I8:      mean=12.96,     variance=183.6,     min=0.0,    max=49.0</span>
<span class="err">FEATURE I9:      mean=102.42,    variance=38152.34,      min=0.0,    max=2711.0</span>
<span class="err">FEATURE I10:     mean=0.64,      variance=0.5,   min=0.0,    max=4.0</span>
<span class="err">FEATURE I11:     mean=2.78,      variance=23.83,     min=0.0,    max=60.0</span>
<span class="err">FEATURE I12:     mean=1.19,      variance=40.19,     min=0.0,    max=84.0</span>
<span class="err">FEATURE I13:     mean=7.99,      variance=116.35,    min=0.0,    max=97.0</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Pandas version </span>
<span class="n">num_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;I1&#39;</span><span class="p">,</span><span class="s1">&#39;I2&#39;</span><span class="p">,</span><span class="s1">&#39;I3&#39;</span><span class="p">,</span><span class="s1">&#39;I4&#39;</span><span class="p">,</span><span class="s1">&#39;I5&#39;</span><span class="p">,</span><span class="s1">&#39;I6&#39;</span><span class="p">,</span><span class="s1">&#39;I7&#39;</span><span class="p">,</span><span class="s1">&#39;I8&#39;</span><span class="p">,</span><span class="s1">&#39;I9&#39;</span><span class="p">,</span><span class="s1">&#39;I10&#39;</span><span class="p">,</span><span class="s1">&#39;I11&#39;</span><span class="p">,</span><span class="s1">&#39;I12&#39;</span><span class="p">,</span><span class="s1">&#39;I13&#39;</span><span class="p">]</span>
<span class="n">toy_df_num</span> <span class="o">=</span> <span class="n">toy_df</span><span class="p">[</span><span class="n">num_columns</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">toy_df_num</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>I1</th>
      <th>I2</th>
      <th>I3</th>
      <th>I4</th>
      <th>I5</th>
      <th>I6</th>
      <th>I7</th>
      <th>I8</th>
      <th>I9</th>
      <th>I10</th>
      <th>I11</th>
      <th>I12</th>
      <th>I13</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>568.000000</td>
      <td>1000.000000</td>
      <td>787.000000</td>
      <td>779.000000</td>
      <td>9.760000e+02</td>
      <td>770.000000</td>
      <td>963.000000</td>
      <td>1000.000000</td>
      <td>963.000000</td>
      <td>568.000000</td>
      <td>963.000000</td>
      <td>226.000000</td>
      <td>779.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>3.167254</td>
      <td>114.719000</td>
      <td>18.780178</td>
      <td>7.427471</td>
      <td>1.839277e+04</td>
      <td>95.231169</td>
      <td>17.942887</td>
      <td>12.961000</td>
      <td>102.419522</td>
      <td>0.642606</td>
      <td>2.778816</td>
      <td>1.194690</td>
      <td>7.993582</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.834144</td>
      <td>423.568469</td>
      <td>45.047402</td>
      <td>9.280591</td>
      <td>7.009829e+04</td>
      <td>255.131025</td>
      <td>93.826907</td>
      <td>13.556669</td>
      <td>195.427732</td>
      <td>0.705795</td>
      <td>4.884305</td>
      <td>6.353803</td>
      <td>10.793634</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000e+00</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>2.000000</td>
      <td>3.032500e+02</td>
      <td>6.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>10.500000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>6.000000</td>
      <td>4.000000</td>
      <td>2.696000e+03</td>
      <td>28.000000</td>
      <td>3.000000</td>
      <td>8.000000</td>
      <td>39.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>32.000000</td>
      <td>18.000000</td>
      <td>10.000000</td>
      <td>9.703500e+03</td>
      <td>92.750000</td>
      <td>12.000000</td>
      <td>20.000000</td>
      <td>101.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>55.000000</td>
      <td>5123.000000</td>
      <td>648.000000</td>
      <td>77.000000</td>
      <td>1.002457e+06</td>
      <td>4304.000000</td>
      <td>2614.000000</td>
      <td>49.000000</td>
      <td>2711.000000</td>
      <td>4.000000</td>
      <td>60.000000</td>
      <td>84.000000</td>
      <td>97.000000</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="c1"># Take a look at histograms for each numeric feature </span>
<span class="n">toy_df_num</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<table><tr>
    <td> <img src="images/clickthrough/output_36_0.png" alt="Drawing" style="width: 750px;"/> </td>
</tr></table>

<div class="highlight"><pre><span></span><span class="c1"># plot boxplots of each feature vs. the outcome</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax_grid</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">toy_df</span><span class="p">[</span><span class="s1">&#39;Label&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">feature</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">num_columns</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">toy_df_num</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax_grid</span><span class="p">[</span><span class="n">idx</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">idx</span><span class="o">%</span><span class="mi">3</span><span class="p">],</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">ax_grid</span><span class="p">[</span><span class="n">idx</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">idx</span><span class="o">%</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;BoxPlots by Label&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<table><tr>
    <td> <img src="images/clickthrough/output_37_0.png" alt="Drawing" style="width: 750px;"/> </td>
</tr></table>

<div class="highlight"><pre><span></span><span class="c1"># Correlation between numerical features</span>
<span class="n">corr</span> <span class="o">=</span> <span class="n">toy_df_num</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">triu_indices_from</span><span class="p">(</span><span class="n">mask</span><span class="p">)]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">240</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=.</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Correlations between features&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<table><tr>
    <td> <img src="images/clickthrough/output_38_0.png" alt="Drawing" style="width: 750px;"/> </td>
</tr></table>

<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">count_categories</span><span class="p">(</span><span class="n">dataRDD</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">var_position</span><span class="p">,</span> <span class="n">top</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    input: RDD, name and position of a categorical variable </span>

<span class="sd">    output: </span>
<span class="sd">    * number of unique categories in the variable</span>
<span class="sd">    * counts of each category occurance by label</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># counting category occurance within each categorical feature </span>
    <span class="n">count_per_category</span> <span class="o">=</span> <span class="n">dataRDD</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">var_position</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> \
                                           <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">:</span> <span class="n">x</span><span class="o">+</span><span class="n">y</span><span class="p">)</span> \
                                           <span class="o">.</span><span class="n">sortBy</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># counting number of unique values within the categorical variable</span>
    <span class="n">num_unique_values</span> <span class="o">=</span> <span class="n">count_per_category</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">distinct</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Unique values within the category:&#39;</span><span class="p">,</span> <span class="n">num_unique_values</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
    <span class="n">top_x</span> <span class="o">=</span> <span class="n">count_per_category</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">top</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top </span><span class="si">{}</span><span class="s1"> categories by count:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">top</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">top_x</span><span class="p">:</span> 
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Category: </span><span class="si">{}</span><span class="s1">; Count: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># TOY DATA</span>
<span class="k">for</span> <span class="n">var_position</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">FIELDS</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">var_position</span> <span class="o">&gt;</span> <span class="mi">12</span> <span class="ow">and</span> <span class="n">var_position</span> <span class="o">&lt;</span> <span class="mi">39</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;VARIABLE </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">var</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">count_categories</span><span class="p">(</span><span class="n">toyRDDCached</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">var_position</span><span class="o">=</span><span class="n">var_position</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nt">VARIABLE</span> <span class="nt">C1</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">57</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">05db9164</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">485</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">68fd1e64</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">146</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5a9ed9b0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">103</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8cf07265</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">51</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">be589b51</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">41</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5bfa8ab5</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">27</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f473b8dc</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">20</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">87552397</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">39af2607</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9a89b36c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>


<span class="nt">VARIABLE</span> <span class="nt">C2</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">193</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">38a947a1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">114</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1cfdf714</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">50</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">287130e0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">46</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">38d50e09</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">46</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">207b2d81</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">37</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">09e68b86</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">33</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">421b43cd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">33</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">4f25e98b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">29</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">89ddfee8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">27</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">58e67aaf</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">27</span>


<span class="nt">VARIABLE</span> <span class="nt">C3</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">771</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d032c263</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">02cf9876</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b00d1501</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">77f2f2e5</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">aa8c1539</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2cbec47f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7da86e4b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9143c832</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b1ecc6c4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C4</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">660</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">29998ed1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c18be181</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d16679b9</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">25</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">85dd697c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">17</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">13508380</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f922efad</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e3cc371a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3e2bfbda</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b733e495</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C5</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">26</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">25c83c98</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">653</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">4cf72387</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">170</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">43b19349</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">56</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">384874ce</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">41</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">0942e0a7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">17</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">30903e74</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">17</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f281d2a7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b0530c50</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b2241560</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">26eb6185</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">2</span>


<span class="nt">VARIABLE</span> <span class="nt">C6</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">7</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7e0ccccf</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">388</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">fbad5c96</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">207</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">fe6b92e5</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">185</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">134</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">6f6d9be8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">37</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">13718bbd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3bf701e7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">21</span>


<span class="nt">VARIABLE</span> <span class="nt">C7</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">723</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1c86e0eb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">30</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7195046d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">90a2c015</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">81bb0302</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">468a0854</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">dc7659bd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5e64ce5f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d2dbdfe6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f00bddf8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">88002ee1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>


<span class="nt">VARIABLE</span> <span class="nt">C8</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">35</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">0b153874</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">597</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5b392875</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">163</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1f89b562</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">69</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">37e4aa92</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">37</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">51d76abe</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">25</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">062b5529</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">20</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c8ddd494</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">6c41e35e</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">985e3fcb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">64523cfa</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>


<span class="nt">VARIABLE</span> <span class="nt">C9</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">2</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">a73ee510</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">900</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7cc72ec2</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">100</span>


<span class="nt">VARIABLE</span> <span class="nt">C10</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">613</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3b08e48b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">216</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">fbbf2c95</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">16</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5ba575e7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">efea433b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">67eea4ef</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">49d1ad89</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">03e48276</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">474773a7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f9065d00</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">935a36f0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>


<span class="nt">VARIABLE</span> <span class="nt">C11</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">601</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">755e4a50</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">36</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">4d8549da</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7f8ffe57</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e51ddf94</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b7094596</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1054ae5c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">a7b606c4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8b94178b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">0f736a0c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7e40f08a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>


<span class="nt">VARIABLE</span> <span class="nt">C12</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">736</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">6aaba33c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">dfbb09fb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8fe001f4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e0d76380</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9f32b866</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d8c29807</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">21a23bfe</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">ed397d6b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">ae1bb660</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C13</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">549</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5978055e</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">36</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3516f6e6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">16</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">51b97b8f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1aa94af3</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">46f42a63</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">740c210d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">025225f2</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1f9d2c38</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">6e5da64f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">eae197fd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>


<span class="nt">VARIABLE</span> <span class="nt">C14</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">18</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b28479f6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">367</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">07d13a8f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">320</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1adce6ef</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">156</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">64c94865</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">47</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">cfef1c29</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">31</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">051219e6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">26</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d2dfe871</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8ceecbc8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f862f261</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">ad1cc976</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C15</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">553</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2d0bb053</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">21</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d345b1a0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">310d155b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">14</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">42b3012c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">52baadf5</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">10040656</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f3002fbd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">10935a85</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e1ac77f7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3628a186</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>


<span class="nt">VARIABLE</span> <span class="nt">C16</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">707</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b041b04a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">84898b2a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">36103458</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1203a270</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">31ca40b6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c64d548f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">587267a3</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c4de5bba</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">01adbab4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C17</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">9</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e5ba7672</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">497</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">d4bb7bd8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">115</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">07c540c4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">109</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3486227d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">67</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1e88c74f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">53</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">776ce399</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">51</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8efede7f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">44</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">27c07bd6</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">40</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2005abd1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">24</span>


<span class="nt">VARIABLE</span> <span class="nt">C18</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">392</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e88ffc9d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">43</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">891589e7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">37</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2804effd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">33</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c21c3e4c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">27</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5bb2ec8e</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">23</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">582152eb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">22</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5aed7436</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">22</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">7ef5affa</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">18</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">395856b0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">16</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">fffe2a63</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>


<span class="nt">VARIABLE</span> <span class="nt">C19</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">128</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">422</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">21ddcdc9</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">358</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">55dd3565</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">20</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">712d530c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5b885066</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9437f62f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">cf99e5de</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">04de9d96</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3014a4b1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1d1eb838</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>


<span class="nt">VARIABLE</span> <span class="nt">C20</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">4</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">422</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">a458ea53</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">209</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b1252a9d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">187</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5840adea</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">182</span>


<span class="nt">VARIABLE</span> <span class="nt">C21</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">724</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">723b4dfd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">0014c32a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e587c466</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">13</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">73d06dde</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">12</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">5f957280</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">dfcfc3fa</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">10</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c2a93b37</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">8</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">deaf6b52</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">0429f84b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>


<span class="nt">VARIABLE</span> <span class="nt">C22</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">6</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">745</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">ad3062eb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">145</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c9d4222a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">94</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8ec974f4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">78e2e389</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c0061c6d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">3</span>


<span class="nt">VARIABLE</span> <span class="nt">C23</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">12</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">32c7478e</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">447</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3a171ecb</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">199</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">423fab69</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">111</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">bcdee96c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">81</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">be7c41b4</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">63</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c7dc6720</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">47</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">55dd3565</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">20</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">dbb486d7</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">16</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c3dc6cef</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">93bad2c0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">5</span>


<span class="nt">VARIABLE</span> <span class="nt">C24</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">489</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3fdb382b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">56</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b34f3128</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">50</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">1793a828</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">49</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">34</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">3b183c5c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">31</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">aee52b6f</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">25</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">45ab94c8</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">22</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9117a34a</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">19</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">df487a73</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">16</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">8fc66e78</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>


<span class="nt">VARIABLE</span> <span class="nt">C25</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">30</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">422</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">001f3601</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">135</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">e8b83407</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">112</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">ea9a246c</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">84</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">cb079c2d</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">44</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">f0f449dd</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">35</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">445bbe3b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">30</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">010f6491</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">29</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2bf691b1</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">9b3e8820</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">28</span>


<span class="nt">VARIABLE</span> <span class="nt">C26</span>

<span class="nt">Unique</span> <span class="nt">values</span> <span class="nt">within</span> <span class="nt">the</span> <span class="nt">category</span><span class="o">:</span> <span class="nt">375</span>

<span class="nt">Top</span> <span class="nt">10</span> <span class="nt">categories</span> <span class="nt">by</span> <span class="nt">count</span><span class="o">:</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">null</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">422</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">49d68486</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">38</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">2fede552</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">22</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c27f155b</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">19</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">c84c4aec</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">15</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">984e0db0</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">aa5f0a15</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">11</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">b7d9c3bc</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">9</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">6c27a535</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">7</span>
<span class="nt">Category</span><span class="o">:</span> <span class="nt">56be3401</span><span class="o">;</span> <span class="nt">Count</span><span class="o">:</span> <span class="nt">6</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Bar graphs of category counts within each categorical variable by label</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">40</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">fno</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># axes are in a two-dimensional array, indexed by [row, col]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">13</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">fno</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">col</span> <span class="o">=</span> <span class="s2">&quot;C&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">fno</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s2">&quot;Label&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">toy_df</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s2">&quot;Greens_d&quot;</span><span class="p">,</span>
                  <span class="n">order</span><span class="o">=</span><span class="n">toy_df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">])</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Count By C&#39;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">fno</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39; Label&#39;</span><span class="p">)</span>
</pre></div>


<table><tr>
    <td> <img src="images/clickthrough/output_41_0.png" alt="Drawing" style="width: 750px;"/> </td>
</tr></table>

<h3>Section 4 - Algorithm Implementation</h3>
<p>In this section we build a gradient-boosted decision tree using Spark ML. The spark implementation follows the Friedman algorithm routine previously discussed in section 2. The documentation, along with a link to the API, can be found here: https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier.</p>
<p>A lengthier tutorial for building pipelines and models using Spark can be found here: https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa. That tutorial borrows from another notebook located here: https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html.</p>
<p>Because Gradient Boost is a sequential model (need tree_1 to compute tree_2) it is not as prone to parallel implementation as random forests are. In the Spark implementation the individual tree building tasks are parallelized. This notion causes the training times in Gradient Boost to exceed those of Random Forest. Parallelizing individual tree building in Spark follows the PLANET model as outlined by Google [Panda, B., Herbach, J., Basu, S., &amp; Bayardo, R. (2009). PLANET: Massively Parallel Learning of Tree Ensembles with MapReduce. Lyon: ACM.]. This technique uses a central controller that provides the tree structure and decides on the optimum split given the information gain from various split points. As detailed in section 2, tree learning is a greedy algorithm in which all split points across all variables must be considered to determine the optimum split (Brieman's technique aids in this greedy approach slightly for unordered variables). It is at this step that parallel processing can help in order to analyze all potential splits and determine the best. Listed below is a detail of the map and reduce phase broken up by ordered or unordered variables. </p>
<p>Controller: The controller lies outside of a map-reduce job and keeps track of the overall tree structure, along with the training set for each node (to compute the split decision) and the size of the splits. The controller proceeds throughout the training set calling map-reduce jobs at each node in order to find the most viable split point</p>
<p>Map Phase: 
 - Ordered lists: From before we know that we need to split at every point along an ordered list in order to find the true optimum split point. Because MapReduce breaks up the input data - it isn't possible to assess where the split point lies. Therefore PLANET simplifies the process slightly by (prior to the distributed job) computing equi-distant histogram for every ordered feature. The splits are then taken at the histogram buckets. While there is a tradeoff using this approach for absolute best split point - the computational cost savings are generally worth it. The map phase then splits at each feature and each value and emits a key, value pair of the form ((node, feature, split point), (sum of y values, sum of squared y values, total length that have value less than s)). 
 - Unordered lists: The map phase outputs key, value pairs of the form ((node, feature), (value, ((sum of y values, sum of squared y values, total length that have value less than s))). The key difference between these two scenarios is that the split value is located in the value for unordered lists and in the key for ordered lists. This falls back to Brieman's technique and requiring unordered lists to be sorted by y value to determine split points. 
 - The aggregated tuple (sum of y values, sum of squared y values, total length that have value less than s) is also output with a key value of node in order for the reducer phase to compare information gain on the various splits</p>
<p>Reduce Phase: 
 - The reducer is split into a series of summations based on the key value format: node, (node, feature), (node, feature, split point). Based on this data it then sums over the aggregated tuple format emitted in all three scenarios in order to determine the optimum split point
 - The output of the reducer is the best split it has seen for each node. This information along with the average y value and size of left and right branches is emited to the controller to further build the tree structure</p>
<p>Mentioned above, for Gradient Boosted Trees Frieman recommended a technique he called TreeBoost in which each leaf was given a different optimum constant update, rather than an average for the overall tree [Friedman, J. (1999). Greedy Function Approximation: A Gradient Boosting Machine. Stanford: Stanford University.]. In the current Spark GradientBoost algorithm, this approach is not utilized and a single parameter is used for the entire tree structure. Implementing TreeBoost is likely to improve overall model accuracy and is saved for a later step. </p>
<p>Below we utilize the Spark ML library in order to fit a gradient boosted tree on the CLR dataset. </p>
<h4>Preprocessing</h4>
<p>First, we import the modules we'll need and read the data into a dataframe.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyspark.sql.functions</span>

<span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="kn">import</span> <span class="n">GBTClassifier</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="kn">import</span> <span class="n">OneHotEncoderEstimator</span><span class="p">,</span> <span class="n">StringIndexer</span><span class="p">,</span> <span class="n">VectorAssembler</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">BinaryClassificationEvaluator</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.tuning</span> <span class="kn">import</span> <span class="n">CrossValidator</span><span class="p">,</span> <span class="n">ParamGridBuilder</span>

<span class="n">ON_CLUSTER</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># flag to determine whether to read from a GCP bucket</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">ON_CLUSTER</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;gs://w61-ucb2/data/train.txt&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;./data/train.txt&quot;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">inferSchema</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># create a small sample for local work</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="o">.</span><span class="mi">0001</span><span class="p">,</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>


<p>Next, we need to transform the data into a format suitable for a GBTClassifier. We'll do this by creating a pipeline of transformations.</p>
<div class="highlight"><pre><span></span><span class="n">stages</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># the stages in the pipeline</span>
</pre></div>


<p>We first convert the categorical features into one-hot encoded vectors. However, as we saw in the EDA above, some features have many millions of unique values. It is infeasible to one-hot encode all of these due to memory constraints, and these features would likely make for poor split points in any case. Thus, we'll initially use only the categorical features that have fewer than 32 unique values, which is the default number of maximum bins used by the GBTClassifier.</p>
<div class="highlight"><pre><span></span><span class="n">categoricalColumns</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;_c</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">40</span><span class="p">)]</span>
<span class="n">countsByCol</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># get approximate distinct counts for each of the categorical features</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categoricalColumns</span><span class="p">:</span>
    <span class="n">cnt</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span>
        <span class="n">pyspark</span><span class="o">.</span><span class="n">sql</span><span class="o">.</span><span class="n">functions</span><span class="o">.</span><span class="n">approx_count_distinct</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">])</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">col</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

    <span class="c1"># store the columns name and the count</span>
    <span class="n">countsByCol</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">cnt</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">col</span><span class="p">])</span> <span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># get features that have fewer than 50 unique values</span>
<span class="n">categoricalColumnsToEncode</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">countsByCol</span> <span class="k">if</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">categoricalColumnsToEncode</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">[&#39;_c19&#39;, &#39;_c22&#39;, &#39;_c27&#39;, &#39;_c30&#39;, &#39;_c33&#39;, &#39;_c35&#39;, &#39;_c36&#39;]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># encode the subset of categorical columns</span>
<span class="k">for</span> <span class="n">categoricalCol</span> <span class="ow">in</span> <span class="n">categoricalColumnsToEncode</span><span class="p">:</span>

    <span class="c1"># index the categories</span>
    <span class="n">stringIndexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span>
        <span class="n">inputCol</span> <span class="o">=</span> <span class="n">categoricalCol</span><span class="p">,</span> 
        <span class="n">outputCol</span> <span class="o">=</span> <span class="n">categoricalCol</span> <span class="o">+</span> <span class="s2">&quot;Index&quot;</span><span class="p">,</span>
        <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;keep&quot;</span>
    <span class="p">)</span>

    <span class="c1"># convert the indices into binary SparseVectors</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoderEstimator</span><span class="p">(</span>
        <span class="n">inputCols</span><span class="o">=</span><span class="p">[</span><span class="n">stringIndexer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">()],</span> 
        <span class="n">outputCols</span><span class="o">=</span><span class="p">[</span><span class="n">categoricalCol</span> <span class="o">+</span> <span class="s2">&quot;classVec&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># add the stage</span>
    <span class="n">stages</span> <span class="o">+=</span> <span class="p">[</span><span class="n">stringIndexer</span><span class="p">,</span> <span class="n">encoder</span><span class="p">]</span>
</pre></div>


<p>We then combine the categorical and numeric columns into a feature vector.</p>
<div class="highlight"><pre><span></span><span class="c1"># extract the encoded categorical features from the dataframe </span>
<span class="c1"># and combine with the continuous features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="o">+</span> <span class="s2">&quot;classVec&quot;</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">categoricalColumnsToEncode</span><span class="p">]</span> <span class="o">+</span> \
                <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;_c</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">14</span><span class="p">)]</span>

<span class="c1"># create the feature vector, preserving rows that contain missing data.</span>
<span class="n">assembler</span> <span class="o">=</span> <span class="n">VectorAssembler</span><span class="p">(</span>
    <span class="n">inputCols</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> 
    <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">,</span> 
    <span class="n">handleInvalid</span><span class="o">=</span><span class="s2">&quot;keep&quot;</span>
<span class="p">)</span>

<span class="c1"># add the assembler to the stages of the pipeline</span>
<span class="n">stages</span> <span class="o">+=</span> <span class="p">[</span><span class="n">assembler</span><span class="p">]</span>
</pre></div>


<p>Finally, we convert the dataset labels into label indices.</p>
<div class="highlight"><pre><span></span><span class="c1"># convert label into indices</span>
<span class="n">labelIndexer</span> <span class="o">=</span> <span class="n">StringIndexer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;_c0&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">stages</span> <span class="o">+=</span> <span class="p">[</span><span class="n">labelIndexer</span><span class="p">]</span>
</pre></div>


<p>All of the transformations that we need to perform to build a GBT now exist as stages, which we'll next evaluate in a pipeline.</p>
<div class="highlight"><pre><span></span><span class="n">preppedDF</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Pipeline</span><span class="p">()</span>
    <span class="o">.</span><span class="n">setStages</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
    <span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
    <span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>


<h4>Initial GBT model</h4>
<p>We'll next perform a single split of the data into training and test sets, fit a GBT to the training data using the default parameters and evaluate the performance on the test data.</p>
<div class="highlight"><pre><span></span><span class="c1"># split the data</span>
<span class="n">trainData</span><span class="p">,</span> <span class="n">testData</span> <span class="o">=</span> <span class="n">preppedDF</span><span class="o">.</span><span class="n">randomSplit</span><span class="p">([</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">],</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>

<span class="c1"># create and train the classifier</span>
<span class="n">gbtModel</span> <span class="o">=</span> <span class="n">GBTClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span>

<span class="c1"># make predictions on the test data</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">gbtModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testData</span><span class="p">)</span>
</pre></div>


<p>In order to compare this initial model to future iterations, get the AUROC score.</p>
<div class="highlight"><pre><span></span><span class="c1"># get the auroc for the default model</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">BinaryClassificationEvaluator</span><span class="p">(</span><span class="n">labelCol</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">auroc</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="p">{</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">metricName</span><span class="p">:</span> <span class="s2">&quot;areaUnderROC&quot;</span> <span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test Area Under ROC: </span><span class="si">{</span><span class="n">auroc</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Test Area Under ROC: 0.7073676650780636</span>
</pre></div>


<p>We'll also create a function to give a better sense of the model's performance.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_counts</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Get the counts of label and prediction agreement &quot;&quot;&quot;</span>

    <span class="c1"># split the dataframe into correct and incorrect predictions</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="n">predictions</span><span class="o">.</span><span class="n">prediction</span><span class="p">)</span>
    <span class="n">incorrect</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">predictions</span><span class="o">.</span><span class="n">label</span> <span class="o">!=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">prediction</span><span class="p">)</span>

    <span class="c1"># get the various counts needed to calculate metrics</span>
    <span class="n">true_positives_cnt</span> <span class="o">=</span> <span class="n">correct</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">correct</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">true_negatives_cnt</span> <span class="o">=</span> <span class="n">correct</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">correct</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">false_positives_cnt</span> <span class="o">=</span> <span class="n">incorrect</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">incorrect</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
    <span class="n">false_negatives_cnt</span> <span class="o">=</span> <span class="n">incorrect</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">incorrect</span><span class="o">.</span><span class="n">label</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">true_positives_cnt</span><span class="p">,</span> <span class="n">true_negatives_cnt</span><span class="p">,</span> <span class="n">false_positives_cnt</span><span class="p">,</span> <span class="n">false_negatives_cnt</span>

<span class="k">def</span> <span class="nf">get_scores</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Get the evaluation scores &quot;&quot;&quot;</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">tn</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">get_counts</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

    <span class="c1"># calculate the metrics </span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">tn</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">tn</span> <span class="o">+</span> <span class="n">fp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fp</span><span class="p">)</span>

    <span class="n">recall</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">/</span> <span class="p">(</span><span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span><span class="p">)</span>

    <span class="n">f1_score</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">recall</span> <span class="o">*</span> <span class="n">precision</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">recall</span> <span class="o">+</span> <span class="n">precision</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="k">def</span> <span class="nf">print_eval_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Print performance metrics.</span>

<span class="sd">        Args:</span>
<span class="sd">            predictions - a DataFrame with model predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">accuracy</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">get_scores</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>

    <span class="c1"># print the results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test accuracy: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">accuracy</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test precision: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test recall: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test F1 score: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">f1_score</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">print_eval_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Test accuracy: 0.76</span>
<span class="err">Test precision: 0.598</span>
<span class="err">Test recall: 0.191</span>
<span class="err">Test F1 score: 0.289</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">gbtModel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;gs://w61-ucb2/data/gbtModel&quot;</span><span class="p">)</span>
</pre></div>


<h4>Further Model Improvements</h4>
<p>There are a number of potential issues with out initial model. First, although we used a random split to create the training and test sets, it is always possible with a single split that there will be anomalies that cause the two sets to differ in ways that cause us to misestimate the model's performance on the test data. To address this problem, we will use 3-fold cross validation below in order to evaluate the model using 3 different splits.</p>
<p>Second, it is possible that the default hyperparameters are not the best hyperparameters for this data. In particular, the model above trains 20 trees (maxIter), with a height of 5 or  $2^5=32$ maximum leaves (maxDepth), and uses a learning rate of 0.1. Below, we'll experiment with different permutations of these parameters and select the best model.</p>
<div class="highlight"><pre><span></span><span class="c1"># specify the parameters over which to search</span>
<span class="n">gbt</span> <span class="o">=</span> <span class="n">GBTClassifier</span><span class="p">()</span>
<span class="n">paramGrid</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">ParamGridBuilder</span><span class="p">()</span>
    <span class="o">.</span><span class="n">addGrid</span><span class="p">(</span><span class="n">gbt</span><span class="o">.</span><span class="n">maxIter</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
    <span class="o">.</span><span class="n">addGrid</span><span class="p">(</span><span class="n">gbt</span><span class="o">.</span><span class="n">maxDepth</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
    <span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># setup 3-fold cross-validation for each model</span>
<span class="n">crossVal</span> <span class="o">=</span> <span class="n">CrossValidator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">GBTClassifier</span><span class="p">(),</span> 
    <span class="n">estimatorParamMaps</span><span class="o">=</span><span class="n">paramGrid</span><span class="p">,</span>
    <span class="n">evaluator</span><span class="o">=</span><span class="n">BinaryClassificationEvaluator</span><span class="p">(),</span>
    <span class="n">numFolds</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
</pre></div>


<p>Having initialized the objects we need, we train the models and select the one with the highest score.</p>
<div class="highlight"><pre><span></span><span class="n">cvModel</span> <span class="o">=</span> <span class="n">crossVal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">trainData</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">cvModel</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">testData</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">print_eval_metrics</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Test accuracy: 0.761</span>
<span class="err">Test precision: 0.603</span>
<span class="err">Test recall: 0.196</span>
<span class="err">Test F1 score: 0.296</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">0.710653928067178</span>
</pre></div>


<p>We see a slight improvement in the AUROC score ($0.710 - 0.707 = 0.003$), the test accuracy $(0.761 - 0.76 = 0.001)$ and the f1 score ($0.296 - 0.289 = 0.007$) with this model.</p>
<p>We'll now inspect the parameters that correspond to the best model.</p>
<div class="highlight"><pre><span></span><span class="n">bestModel</span> <span class="o">=</span> <span class="n">cvModel</span><span class="o">.</span><span class="n">bestModel</span>
<span class="n">param_map</span> <span class="o">=</span> <span class="n">bestModel</span><span class="o">.</span><span class="n">extractParamMap</span><span class="p">()</span>
<span class="n">num_trees</span> <span class="o">=</span> <span class="n">param_map</span><span class="p">[</span><span class="n">bestModel</span><span class="o">.</span><span class="n">getParam</span><span class="p">(</span><span class="s2">&quot;maxIter&quot;</span><span class="p">)]</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="n">param_map</span><span class="p">[</span><span class="n">bestModel</span><span class="o">.</span><span class="n">getParam</span><span class="p">(</span><span class="s2">&quot;maxDepth&quot;</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of trees: </span><span class="si">{</span><span class="n">num_trees</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Maximum height of tree: </span><span class="si">{</span><span class="n">max_depth</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Number of trees: 20</span>
<span class="err">Maximum height of tree: 5</span>
</pre></div>


<p>We see that the maximum depth of the tree is 5 and the number of iterations (i.e. the height of the tree) is 20. The results indicate that adding more trees resulted in overfitting the model for this dataset. The parameters for the best model in fact match those used in the default model above, so the improved scores are actually a result of using cross-validation.</p>
<div class="highlight"><pre><span></span><span class="c1"># save the model for future use</span>
<span class="n">cvModel</span><span class="o">.</span><span class="n">bestModel</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;gs://w61-ucb2/data/gbtModelBest&#39;</span><span class="p">)</span>
</pre></div>


<p><strong>Gradient Boost Results and Discussion</strong></p>
<p><strong>Methods to Implement in Future Work</strong></p>
<p>Gradient boost techniques are a very popular machine learning implementation and have observed very good results in some of the data science competition sites. There has therefore been a number of improvements and iterations on the gradient boost techniques presented here that could aid in the development of a more accurate gradient boost model: 
 - Handling of sparse data / matrix: As shown in the EDA section and as generally accepted with CTR data, many of the features are sparse (empty) or missing (NAN). When building a decision tree, we use an encoding routine to separate categorical features into n_unique features. This causes the feature space to get very large (especially when there are a number of categories as was the case in this dataset (1293 unique values in one feature space)). If a one-hot encoding routine is utilized this causes the feature space to become very sparse (number of zero values) as most datapoints won't contain any data. There is also the problem of training on NAN values which isn't possible. In this example we either: (a) imputed the mean of a numeric vector and used that to fill NAN values (b) assumed the value of zero for all missing data in categorical features. One common method for addressing the sparsity issue is to encode a category into a series of bins rather than one-hot encoding. In this CTR data our categorical features were hash values rather than the original dataset. Because of this, we did not choose to employ a binning technique as we were uncertain of the algorithm to create the hash and whether there was validity in binning values based on their hash value. Given another training set where we had access to the raw value and can bin by value this is a worthy technique. XG-Boost specifically handles sparse data well by performing what the authors entitled 'sparsity-aware split finding'. The basic premise used in XG-boost is to utilize a default direction when encountering NAN or zero values for a particular feature. This default direction is determined by analyzing all missing values for that feature and determining the most appropriate direction [Chen, T., &amp; Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Cornell University.]. 
 - Alternatives to One-Hot-Encoding: We've already mentioned the potential to use binning rather than one-hot encoding. Another popular technique is to use a target statistic - such as the expected value of the output parameter based on the category value or alternatively for the bin. The technique is similar to binning except the value is replaced with a target statistic. There are a number of alternative methods to compute the target statistic that have been utilized to optimize training and prevent target leakage [Prokhorenkova, L., Gusev, G., Vorobev, A., Dorogush, A. V., &amp; Gulin, A. (2019). CatBoost: unbiased boosting with categorical features.]. 
 - TreeBoost: As mentioned prior to implementing gradient boost in Spark. The current library doesn't make use of separate multiplier values for each leaf node as recommended by Friedman. Implementing TreeBoost has been shown to increase the accuracy of gradient boost models 
 - Individual Tree Optimization: Gradient boost relies on a number of weak estimators to create a good prediction in aggregate. There are a number of methods we can employ to allow our weak estimator to more accurately assess each problem and therefore optimize the ensemble: 
     - Depth of the trees: This can lead to overfitting but can also improve individual prediction which can benefit the aggregate model
     - Minimum number of examples per leaf: Similar to depth of the tree, can lead to overfitting and or model improvement depending on the problem
 - Shrinkage: In the Spark ML implementation we chose a learning rate that tempered the adjustments made on sequential models fit to the residuals. We can further refine this value to optimize model performance
 - Regularization: Use L1 and L2 regularization techniques to penalize complex models. This is assessed in the loss functino by adding regularization terms to the end of the loss function corresponding to L1 and L2 regularization: $$L = loss function + \frac{1}{2} \lambda \sum w_j^2 + \alpha \sum |w_j|$$ Where $\lambda$ and $\alpha$ are the L2 and L1 regularization terms respectively. </p></p>
        </div>
    </div>

<div class="fh5co-narrow-content">
<div class="animate-box" data-animate-effect="fadeInLeft">
    <h2><!-- <i class="icon-speech-bubble"></i>  -->Comments</h2>
</div>
<div class="animate-box" data-animate-effect="fadeInLeft">
    <div id="disqus_thread"></div>
</div>

<script>
var disqus_config = function () { 
  this.language = "english";
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript><a href="https://disqus.com/?ref_noscript">Please enable JavaScript to view the comments powered by Disqus.</a></noscript>
<div class="fh5co-footer">
    <p><small>&copy; 2016 Blend Free HTML5. All Rights Reserved.</span> <span>Designed by <a href="http://freehtml5.co/" target="_blank">FreeHTML5.co</a></span>
    <br /><span>Pelican Theme by: <a href="https://github.com/claudio-walser/pelican-fh5co-marble" target="_blank">Claudio Walser</a></span></small></p>

</div>                
        </div>
    </div>

    <!-- jQuery -->
    <script src="https://aaron-j-olson.com/theme/js/jquery.min.js"></script>
    <!-- jQuery Easing -->
    <script src="https://aaron-j-olson.com/theme/js/jquery.easing.1.3.js"></script>
    <!-- Bootstrap -->
    <script src="https://aaron-j-olson.com/theme/js/bootstrap.min.js"></script>
    <!-- Waypoints -->
    <script src="https://aaron-j-olson.com/theme/js/jquery.waypoints.min.js"></script>
    <!-- Flexslider -->
    <script src="https://aaron-j-olson.com/theme/js/jquery.flexslider-min.js"></script>


    <!-- MAIN JS -->
    <script src="https://aaron-j-olson.com/theme/js/main.js"></script>
    </body>
</html>
